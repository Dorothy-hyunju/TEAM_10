"""
RAG ì‹œìŠ¤í…œ - GPT ë™ì  ë™ì˜ì–´ + Few-shot ê°•í™” ë²„ì „
íŒŒì¼: src/rag_system.py

ì£¼ìš” ê°œì„ :
1. GPT ê¸°ë°˜ ë™ì  ë™ì˜ì–´ ìƒì„±
2. Few-shot í•™ìŠµ ì ìš©
3. ìœ ì‚¬ë„ ì ìˆ˜ ê·¹ëŒ€í™”
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import chromadb
from chromadb.config import Settings
import numpy as np
from datetime import datetime
import time
import re

# í•œêµ­ì–´ íŠ¹í™” ì„ë² ë”©
try:
    from sentence_transformers import SentenceTransformer
    import torch
    HUGGINGFACE_AVAILABLE = True
except ImportError:
    HUGGINGFACE_AVAILABLE = False

# OpenAI í´ë¼ì´ì–¸íŠ¸
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
import sys
sys.path.append(str(Path(__file__).parent.parent))
from src.data_loader import MattressDataLoader

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class GPTSynonymGenerator:
    """GPT ê¸°ë°˜ ë™ì  ë™ì˜ì–´ ìƒì„±ê¸°"""
    
    def __init__(self, openai_client=None):
        self.client = openai_client
        self.synonym_cache = {}
        self.few_shot_examples = self._get_few_shot_examples()
    
    def _get_few_shot_examples(self) -> str:
        """Few-shot í•™ìŠµìš© ë™ì˜ì–´ ìƒì„± ì˜ˆì‹œ"""
        return """
ë§¤íŠ¸ë¦¬ìŠ¤ ê´€ë ¨ ë™ì˜ì–´ ìƒì„± ì˜ˆì‹œë“¤:

ì…ë ¥: "ë”±ë”±í•œ"
ì¶œë ¥: ["ë‹¨ë‹¨í•œ", "í•˜ë“œ", "ê²¬ê³ í•œ", "íƒ„íƒ„í•œ", "íŒ", "ê°•í•œ", "íŠ¼íŠ¼í•œ", "solid", "firm"]

ì…ë ¥: "í—ˆë¦¬í†µì¦"  
ì¶œë ¥: ["ìš”í†µ", "í—ˆë¦¬ì•„í””", "ìš”ì¶”í†µì¦", "í—ˆë¦¬ë””ìŠ¤í¬", "ì²™ì¶”í†µì¦", "ë“±í†µì¦", "ìš”ì¶”ì§ˆí™˜", "í—ˆë¦¬ë¬¸ì œ"]

ì…ë ¥: "ì‹œì›í•œ"
ì¶œë ¥: ["ì¿¨ë§", "ëƒ‰ê°", "í†µí’", "ì„œëŠ˜í•œ", "ì°¨ê°€ìš´", "ì¿¨", "ì‹œì›í•¨", "cool", "ëƒ‰ê¸°"]

ì…ë ¥: "ë©”ëª¨ë¦¬í¼"
ì¶œë ¥: ["ê¸°ì–µì¥ì¹˜", "í…œí¼", "ë¹„ìŠ¤ì½”", "í…œí¼í¼", "ê¸°ì–µí¼", "memory foam", "ì íƒ„ì„±í¼", "ì €ë°˜ë°œí¼"]

ì…ë ¥: "ì»¤í”Œ"
ì¶œë ¥: ["ë¶€ë¶€", "ì‹ í˜¼", "ì—°ì¸", "2ì¸", "ë‘˜ì´ì„œ", "ë¶€ë¶€ìš©", "ì»¤í”Œìš©", "íŒŒíŠ¸ë„ˆ", "couple"]

ì…ë ¥: "ì•„ì´"
ì¶œë ¥: ["ì–´ë¦°ì´", "ì•„ê¸°", "ìœ ì•„", "í•™ìƒ", "ì„±ì¥ê¸°", "ì•„ë™", "ì–´ë¦°ì•„ì´", "í‚¤ì¦ˆ", "child"]
"""
    
    def generate_synonyms(self, keyword: str) -> List[str]:
        """GPTë¡œ ë™ì  ë™ì˜ì–´ ìƒì„±"""
        if not self.client:
            return []
        
        if keyword in self.synonym_cache:
            return self.synonym_cache[keyword]
        
        try:
            system_prompt = f"""
ë‹¹ì‹ ì€ ë§¤íŠ¸ë¦¬ìŠ¤ ë„ë©”ì¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ í‚¤ì›Œë“œì˜ ë™ì˜ì–´ì™€ ìœ ì‚¬ì–´ë¥¼ ìƒì„±í•˜ì„¸ìš”.

{self.few_shot_examples}

ê·œì¹™:
1. ë§¤íŠ¸ë¦¬ìŠ¤ ì‡¼í•‘ ë§¥ë½ì—ì„œ ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” í‘œí˜„
2. ì •í™•í•œ ë™ì˜ì–´ 8-10ê°œ ìƒì„±
3. í•œêµ­ì–´ì™€ ì˜ì–´ ëª¨ë‘ í¬í•¨
4. JSON ë°°ì—´ í˜•íƒœë¡œë§Œ ì‘ë‹µ
"""
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"í‚¤ì›Œë“œ: '{keyword}'"}
                ],
                max_tokens=200,
                temperature=0.3
            )
            
            content = response.choices[0].message.content.strip()
            synonyms = json.loads(content)
            
            if isinstance(synonyms, list):
                self.synonym_cache[keyword] = synonyms
                logger.debug(f"GPT ë™ì˜ì–´ ìƒì„±: {keyword} â†’ {len(synonyms)}ê°œ")
                return synonyms
                
        except Exception as e:
            logger.error(f"GPT ë™ì˜ì–´ ìƒì„± ì‹¤íŒ¨: {keyword}, {e}")
        
        return []


class EnhancedKoreanTextPreprocessor:
    """GPT ê°•í™” í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ê¸°"""
    
    def __init__(self, gpt_synonym_generator=None):
        self.gpt_synonym_generator = gpt_synonym_generator
        
        # ê¸°ë³¸ ë¶ˆìš©ì–´
        self.stopwords = {
            'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì˜', 'ì™€', 'ê³¼', 'ë¡œ', 'ìœ¼ë¡œ',
            'ì…ë‹ˆë‹¤', 'ìŠµë‹ˆë‹¤', 'ìˆìŠµë‹ˆë‹¤', 'í•©ë‹ˆë‹¤', 'ë©ë‹ˆë‹¤', 'ìˆì–´ìš”', 'í•´ìš”',
            'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°', 'ë˜í•œ', 'ë˜', 'ê·¸ë˜ì„œ', 'ë”°ë¼ì„œ',
            'ë§¤ìš°', 'ì •ë§', 'ì•„ì£¼', 'ë„ˆë¬´', 'ì¡°ê¸ˆ', 'ì•½ê°„', 'ì¢€', 'ë§ì´'
        }
        
        # í‚¤ì›Œë“œ ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜
        self.keyword_weights = {
            # ê±´ê°• ê´€ë ¨ (ìµœê³  ì¤‘ìš”ë„)
            'í—ˆë¦¬': 5.0, 'ëª©': 5.0, 'í†µì¦': 5.0, 'ë””ìŠ¤í¬': 5.0,
            'ìš”ì¶”': 4.5, 'ì²™ì¶”': 4.5, 'ê²½ì¶”': 4.5,
            
            # ì†Œì¬/íƒ€ì… ê´€ë ¨ (ë†’ì€ ì¤‘ìš”ë„)  
            'ë©”ëª¨ë¦¬í¼': 4.0, 'ë¼í…ìŠ¤': 4.0, 'ìŠ¤í”„ë§': 4.0,
            'í…œí¼': 3.5, 'ì½”ì¼': 3.5,
            
            # ê°ì´‰ ê´€ë ¨ (ë†’ì€ ì¤‘ìš”ë„)
            'ë”±ë”±': 3.5, 'ë¶€ë“œëŸ¬': 3.5, 'ì‹œì›': 3.5,
            'í•˜ë“œ': 3.0, 'ì†Œí”„íŠ¸': 3.0, 'ì¿¨ë§': 3.0
        }
    
    def extract_weighted_keywords(self, text: str) -> List[Tuple[str, float]]:
        """ê°€ì¤‘ì¹˜ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        words = self.normalize_text(text).split()
        
        weighted_keywords = []
        for word in words:
            if len(word) > 1 and word not in self.stopwords:
                weight = self.keyword_weights.get(word, 1.0)
                weighted_keywords.append((word, weight))
        
        # ê°€ì¤‘ì¹˜ ê¸°ì¤€ ì •ë ¬
        return sorted(weighted_keywords, key=lambda x: x[1], reverse=True)
    
    def normalize_text(self, text: str) -> str:
        """í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì •ê·œí™”"""
        if not text:
            return ""
        
        text = text.strip()
        text = re.sub(r'[^\w\sê°€-í£a-zA-Z0-9.,!?%-]', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        text = re.sub(r'(\d+)\s*ë§Œ\s*ì›', r'\1ë§Œì›', text)
        
        return text.strip()
    
    def create_gpt_enhanced_text(self, text: str) -> str:
        """GPT ë™ì˜ì–´ë¥¼ í™œìš©í•œ í…ìŠ¤íŠ¸ ê°•í™”"""
        normalized = self.normalize_text(text)
        enhanced_parts = [normalized]
        
        # ê°€ì¤‘ì¹˜ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ
        weighted_keywords = self.extract_weighted_keywords(normalized)
        
        # GPT ë™ì˜ì–´ ìƒì„± (ìƒìœ„ í‚¤ì›Œë“œë§Œ)
        if self.gpt_synonym_generator:
            for keyword, weight in weighted_keywords[:5]:  # ìƒìœ„ 5ê°œë§Œ
                synonyms = self.gpt_synonym_generator.generate_synonyms(keyword)
                
                if synonyms:
                    # ê°€ì¤‘ì¹˜ì— ë”°ë¼ ë°˜ë³µ íšŸìˆ˜ ê²°ì •
                    repeat_count = min(int(weight), 3)
                    selected_synonyms = synonyms[:6]  # ìƒìœ„ 6ê°œ ë™ì˜ì–´
                    
                    for _ in range(repeat_count):
                        enhanced_parts.extend(selected_synonyms)
        
        # ì¤‘ìš” í‚¤ì›Œë“œ ê°•ì¡°
        priority_keywords = [kw for kw, weight in weighted_keywords if weight >= 3.0]
        enhanced_parts.extend(priority_keywords * 2)  # 2ë²ˆ ë°˜ë³µ
        
        return ' '.join(enhanced_parts)


class FewShotEnhancedEmbeddingManager:
    """Few-shot í•™ìŠµ ê°•í™” ì„ë² ë”© ë§¤ë‹ˆì €"""
    
    def __init__(self, model_name: str = None, gpt_synonym_generator=None):
        if not HUGGINGFACE_AVAILABLE:
            raise ImportError("sentence-transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # í•œêµ­ì–´ ëª¨ë¸ ìš°ì„ ìˆœìœ„
        korean_models = [
            "jhgan/ko-sroberta-multitask",
            "snunlp/KR-SBERT-V40K-klueNLI-augSTS", 
            "BM-K/KoSimCSE-roberta-multitask",
            "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
            "all-MiniLM-L6-v2"
        ]
        
        if model_name:
            korean_models.insert(0, model_name)
        
        # ëª¨ë¸ ë¡œë“œ
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.model = None
        self.model_name = None
        
        for model in korean_models:
            try:
                logger.info(f"ëª¨ë¸ ë¡œë“œ ì‹œë„: {model}")
                self.model = SentenceTransformer(model, device=self.device)
                self.model_name = model
                logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model}")
                break
            except Exception as e:
                logger.warning(f"ëª¨ë¸ {model} ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue
        
        if not self.model:
            raise RuntimeError("ì‚¬ìš© ê°€ëŠ¥í•œ ì„ë² ë”© ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
        
        # ì „ì²˜ë¦¬ê¸° ë° ìºì‹œ ì´ˆê¸°í™”
        self.preprocessor = EnhancedKoreanTextPreprocessor(gpt_synonym_generator)
        self.embedding_cache = {}
        self.few_shot_examples = self._get_few_shot_examples()
        
        logger.info(f"Few-shot ê°•í™” ì„ë² ë”© ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"ëª¨ë¸: {self.model_name}, ë””ë°”ì´ìŠ¤: {self.device}")
    
    def _get_few_shot_examples(self) -> str:
        """Few-shot í•™ìŠµìš© ì¿¼ë¦¬ í™•ì¥ ì˜ˆì‹œ"""
        return """
ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰ ì¿¼ë¦¬ í™•ì¥ ë°©ë²•:

ì›ë³¸: "í—ˆë¦¬ ì•„í”ˆ ì‚¬ëŒ ë§¤íŠ¸ë¦¬ìŠ¤"
í™•ì¥: "í—ˆë¦¬ ì•„í”ˆ ì‚¬ëŒ ë§¤íŠ¸ë¦¬ìŠ¤ ìš”í†µ ì²™ì¶”í†µì¦ í—ˆë¦¬ë””ìŠ¤í¬ ì²´ì••ë¶„ì‚° ì§€ì§€ë ¥ ë”±ë”±í•œ í•˜ë“œ íŒ ì²™ì¶”ì •ë ¬"

ì›ë³¸: "ë”ìœ„ íƒ€ëŠ” ì‚¬ëŒìš©"
í™•ì¥: "ë”ìœ„ íƒ€ëŠ” ì‚¬ëŒìš© ì‹œì›í•œ ì¿¨ë§ ëƒ‰ê° í†µê¸°ì„± ì ¤ë©”ëª¨ë¦¬í¼ ì˜¨ë„ì¡°ì ˆ í†µí’ í™˜ê¸°"

ì›ë³¸: "ì‹ í˜¼ë¶€ë¶€ í‚¹ì‚¬ì´ì¦ˆ"
í™•ì¥: "ì‹ í˜¼ë¶€ë¶€ í‚¹ì‚¬ì´ì¦ˆ ì»¤í”Œ ë¶€ë¶€ ì—°ì¸ 2ì¸ ë™ì‘ê²©ë¦¬ ì§„ë™ì°¨ë‹¨ ë„“ì€ê³µê°„"

ì›ë³¸: "50ë§Œì› ê°€ì„±ë¹„"
í™•ì¥: "50ë§Œì› ê°€ì„±ë¹„ ì˜ˆì‚° ê²½ì œì  í•©ë¦¬ì  ì €ë ´í•œ ì¤‘ê°„ê°€ê²©ëŒ€ ì ë‹¹í•œê°€ê²©"
"""
    
    def generate_few_shot_expansion(self, query: str) -> str:
        """Few-shot í•™ìŠµ ê¸°ë°˜ ì¿¼ë¦¬ í™•ì¥"""
        if not self.preprocessor.gpt_synonym_generator or not self.preprocessor.gpt_synonym_generator.client:
            return query
        
        try:
            system_prompt = f"""
ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰ ì „ë¬¸ê°€ë¡œì„œ ì¿¼ë¦¬ë¥¼ í™•ì¥í•˜ì—¬ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ì„¸ìš”.

{self.few_shot_examples}

ê·œì¹™:
1. ì›ë³¸ ì¿¼ë¦¬ + ë™ì˜ì–´ + ê´€ë ¨ ìš©ì–´
2. ë§¤íŠ¸ë¦¬ìŠ¤ ë„ë©”ì¸ íŠ¹í™” ìš©ì–´ ì‚¬ìš©
3. ê²€ìƒ‰ ì˜ë„ ì •í™•íˆ íŒŒì•…
4. í™•ì¥ëœ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
"""
            
            response = self.preprocessor.gpt_synonym_generator.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"í™•ì¥í•  ì¿¼ë¦¬: '{query}'"}
                ],
                max_tokens=150,
                temperature=0.4
            )
            
            expanded = response.choices[0].message.content.strip()
            logger.debug(f"Few-shot í™•ì¥: {query} â†’ {expanded[:50]}...")
            return expanded
            
        except Exception as e:
            logger.error(f"Few-shot í™•ì¥ ì‹¤íŒ¨: {e}")
            return query
    
    def generate_embedding(self, text: str, use_enhancement: bool = True) -> List[float]:
        """í–¥ìƒëœ ì„ë² ë”© ìƒì„±"""
        cache_key = f"{text}_{use_enhancement}"
        if cache_key in self.embedding_cache:
            return self.embedding_cache[cache_key]
        
        try:
            if not text or not text.strip():
                text = "ë¹ˆ í…ìŠ¤íŠ¸"
            
            if use_enhancement:
                # 1. Few-shot í™•ì¥
                expanded_text = self.generate_few_shot_expansion(text)
                
                # 2. GPT ë™ì˜ì–´ ê°•í™”
                enhanced_text = self.preprocessor.create_gpt_enhanced_text(expanded_text)
            else:
                enhanced_text = self.preprocessor.normalize_text(text)
            
            # ì„ë² ë”© ìƒì„±
            embedding = self.model.encode(
                enhanced_text,
                convert_to_tensor=False,
                normalize_embeddings=True,  # ì •ê·œí™”ë¡œ ìœ ì‚¬ë„ ìµœì í™”
                show_progress_bar=False
            )
            
            if isinstance(embedding, np.ndarray):
                embedding = embedding.tolist()
            
            self.embedding_cache[cache_key] = embedding
            return embedding
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            default_dim = 768 if 'roberta' in self.model_name.lower() else 384
            return [0.0] * default_dim
    
    def generate_embeddings_batch(self, texts: List[str], batch_size: int = 16, 
                                 use_enhancement: bool = True) -> List[List[float]]:
        """ë°°ì¹˜ ì„ë² ë”© ìƒì„±"""
        if not texts:
            return []
        
        embeddings = []
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        processed_texts = []
        for text in texts:
            if use_enhancement:
                expanded = self.generate_few_shot_expansion(text)
                enhanced = self.preprocessor.create_gpt_enhanced_text(expanded)
            else:
                enhanced = self.preprocessor.normalize_text(text)
            processed_texts.append(enhanced)
        
        # ë°°ì¹˜ ì²˜ë¦¬
        for i in range(0, len(processed_texts), batch_size):
            batch_texts = processed_texts[i:i + batch_size]
            
            try:
                batch_embeddings = self.model.encode(
                    batch_texts,
                    convert_to_tensor=False,
                    normalize_embeddings=True,
                    batch_size=min(len(batch_texts), batch_size),
                    show_progress_bar=False
                )
                
                if isinstance(batch_embeddings, np.ndarray):
                    if len(batch_embeddings.shape) == 1:
                        batch_embeddings = [batch_embeddings.tolist()]
                    else:
                        batch_embeddings = batch_embeddings.tolist()
                
                embeddings.extend(batch_embeddings)
                logger.info(f"ë°°ì¹˜ ì„ë² ë”© ì™„ë£Œ: {i + len(batch_texts)}/{len(texts)}")
                
            except Exception as e:
                logger.error(f"ë°°ì¹˜ ì„ë² ë”© ì‹¤íŒ¨: {e}")
                # ê°œë³„ ìƒì„±ìœ¼ë¡œ í´ë°±
                for text in batch_texts:
                    embedding = self.generate_embedding(text, use_enhancement)
                    embeddings.append(embedding)
        
        return embeddings


class ChromaDBManager:
    """ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬"""
    
    def __init__(self, persist_directory: str = "./chroma_db"):
        self.persist_directory = Path(persist_directory)
        self.persist_directory.mkdir(exist_ok=True)
        
        self.client = chromadb.PersistentClient(path=str(self.persist_directory))
        self.collection_name = "enhanced_mattress_collection_v4"
        self.collection = None
        
        logger.info(f"ChromaDB ë§¤ë‹ˆì € ì´ˆê¸°í™”: {self.persist_directory}")
    
    def create_collection(self, reset: bool = False) -> bool:
        """ì»¬ë ‰ì…˜ ìƒì„±"""
        try:
            if reset:
                try:
                    self.client.delete_collection(self.collection_name)
                    logger.info("ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ")
                except:
                    pass
            
            self.collection = self.client.get_or_create_collection(
                name=self.collection_name,
                metadata={"description": "GPT + Few-shot ê°•í™” ë§¤íŠ¸ë¦¬ìŠ¤ ë²¡í„° DB"}
            )
            
            logger.info(f"ì»¬ë ‰ì…˜ '{self.collection_name}' ì¤€ë¹„ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def add_documents(self, documents: List[str], embeddings: List[List[float]], 
                     metadatas: List[Dict], ids: List[str]) -> bool:
        """ë¬¸ì„œ ì¶”ê°€"""
        if not self.collection:
            return False
        
        try:
            self.collection.add(
                documents=documents,
                embeddings=embeddings,
                metadatas=metadatas,
                ids=ids
            )
            
            logger.info(f"ë¬¸ì„œ {len(documents)}ê°œ ì¶”ê°€ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False
    
    def search_similar(self, query_embedding: List[float], n_results: int = 5) -> Dict:
        """ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"""
        if not self.collection:
            return {}
        
        try:
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results
            )
            return results
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_collection_info(self) -> Dict:
        """ì»¬ë ‰ì…˜ ì •ë³´"""
        if not self.collection:
            return {"error": "ì»¬ë ‰ì…˜ ì—†ìŒ"}
        
        try:
            return {
                "name": self.collection_name,
                "count": self.collection.count(),
                "persist_directory": str(self.persist_directory)
            }
        except Exception as e:
            return {"error": str(e)}


class EnhancedMattressRAGSystem:
    """GPT + Few-shot ê°•í™” ë§¤íŠ¸ë¦¬ìŠ¤ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, persist_directory: str = "./chroma_db", 
                 model_name: str = None, openai_api_key: str = None):
        
        # GPT í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        gpt_client = None
        if openai_api_key and OPENAI_AVAILABLE:
            try:
                gpt_client = OpenAI(api_key=openai_api_key)
                logger.info("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as e:
                logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # GPT ë™ì˜ì–´ ìƒì„±ê¸°
        self.gpt_synonym_generator = GPTSynonymGenerator(gpt_client)
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.embedding_manager = FewShotEnhancedEmbeddingManager(
            model_name, self.gpt_synonym_generator
        )
        self.chroma_manager = ChromaDBManager(persist_directory)
        self.data_loader = None
        
        self.is_initialized = False
        self.gpt_available = gpt_client is not None
        
        logger.info("Enhanced RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"GPT ë™ì˜ì–´ ìƒì„±: {'âœ…' if self.gpt_available else 'âŒ'}")
    
    def initialize_with_data(self, data_loader: MattressDataLoader, reset_db: bool = False) -> bool:
        """ë°ì´í„°ë¡œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            logger.info("Enhanced RAG ì‹œìŠ¤í…œ ë°ì´í„° ì´ˆê¸°í™” ì‹œì‘")
            
            self.data_loader = data_loader
            
            if not self.chroma_manager.create_collection(reset=reset_db):
                return False
            
            # ê¸°ì¡´ ë°ì´í„° í™•ì¸
            collection_info = self.chroma_manager.get_collection_info()
            if collection_info.get("count", 0) > 0 and not reset_db:
                logger.info(f"ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©: {collection_info['count']}ê°œ")
                self.is_initialized = True
                return True
            
            # RAG ë°ì´í„° ì „ì²˜ë¦¬
            rag_data = data_loader.preprocess_for_rag()
            if not rag_data:
                return False
            
            documents = [item['search_text'] for item in rag_data]
            metadatas = [item['metadata'] for item in rag_data]
            ids = [item['id'] for item in rag_data]
            
            logger.info(f"ê°•í™”ëœ ì„ë² ë”© ìƒì„± ì‹œì‘: {len(documents)}ê°œ")
            
            # ê°•í™”ëœ ì„ë² ë”© ìƒì„±
            embeddings = self.embedding_manager.generate_embeddings_batch(
                documents, use_enhancement=True
            )
            
            # ChromaDB ì €ì¥
            if self.chroma_manager.add_documents(documents, embeddings, metadatas, ids):
                self.is_initialized = True
                logger.info("âœ… Enhanced RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"Enhanced RAG ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def search_mattresses(self, query: str, n_results: int = 5, 
                         budget_filter: Optional[Tuple[int, int]] = None) -> List[Dict]:
        """ë‹¤ì¤‘ ì „ëµ ê°•í™” ê²€ìƒ‰"""
        if not self.is_initialized:
            return []
        
        try:
            logger.info(f"Enhanced ê²€ìƒ‰ ì‹œì‘: '{query}'")
            
            all_results = {}
            
            # ì „ëµ 1: GPT Few-shot + ë™ì˜ì–´ ê°•í™” ê²€ìƒ‰ (ìµœê³  ê°€ì¤‘ì¹˜)
            enhanced_results = self._search_with_full_enhancement(query, n_results * 2)
            self._add_weighted_results(all_results, enhanced_results, 1.0, 'enhanced')
            
            # ì „ëµ 2: Few-shotë§Œ ì ìš© ê²€ìƒ‰
            few_shot_results = self._search_with_few_shot_only(query, n_results * 2)
            self._add_weighted_results(all_results, few_shot_results, 0.8, 'few_shot')
            
            # ì „ëµ 3: ì›ë³¸ ì¿¼ë¦¬ ê²€ìƒ‰
            original_results = self._search_with_original(query, n_results)
            self._add_weighted_results(all_results, original_results, 0.6, 'original')
            
            # ìµœì¢… ê²°ê³¼ ê³„ì‚°
            final_results = self._calculate_final_results(
                all_results, budget_filter, n_results
            )
            
            logger.info(f"Enhanced ê²€ìƒ‰ ì™„ë£Œ: {len(final_results)}ê°œ")
            return final_results
            
        except Exception as e:
            logger.error(f"Enhanced ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _search_with_full_enhancement(self, query: str, n_results: int) -> Dict:
        """ì™„ì „ ê°•í™” ê²€ìƒ‰ (Few-shot + GPT ë™ì˜ì–´)"""
        embedding = self.embedding_manager.generate_embedding(query, use_enhancement=True)
        return self.chroma_manager.search_similar(embedding, n_results)
    
    def _search_with_few_shot_only(self, query: str, n_results: int) -> Dict:
        """Few-shotë§Œ ì ìš© ê²€ìƒ‰"""
        expanded_query = self.embedding_manager.generate_few_shot_expansion(query)
        embedding = self.embedding_manager.generate_embedding(expanded_query, use_enhancement=False)
        return self.chroma_manager.search_similar(embedding, n_results)
    
    def _search_with_original(self, query: str, n_results: int) -> Dict:
        """ì›ë³¸ ì¿¼ë¦¬ ê²€ìƒ‰"""
        embedding = self.embedding_manager.generate_embedding(query, use_enhancement=False)
        return self.chroma_manager.search_similar(embedding, n_results)
    
    def _add_weighted_results(self, all_results: Dict, search_results: Dict, 
                            weight: float, strategy: str):
        """ê°€ì¤‘ì¹˜ ì ìš© ê²°ê³¼ ì¶”ê°€"""
        if not search_results.get('documents'):
            return
        
        for i in range(len(search_results['documents'][0])):
            doc_id = search_results['ids'][0][i]
            distance = search_results['distances'][0][i]
            weighted_score = (1 - distance) * weight
            
            if doc_id not in all_results:
                all_results[doc_id] = {
                    'metadata': search_results['metadatas'][0][i],
                    'document': search_results['documents'][0][i],
                    'scores': {},
                    'total_score': 0,
                    'strategy_count': 0
                }
            
            all_results[doc_id]['scores'][strategy] = weighted_score
            all_results[doc_id]['total_score'] += weighted_score
            all_results[doc_id]['strategy_count'] += 1
    
    def _calculate_final_results(self, all_results: Dict, 
                               budget_filter: Optional[Tuple[int, int]], 
                               n_results: int) -> List[Dict]:
        """ìµœì¢… ê²°ê³¼ ê³„ì‚°"""
        final_results = []
        
        for doc_id, data in all_results.items():
            metadata = data['metadata']
            price = metadata.get('price', 0)
            
            # ì˜ˆì‚° í•„í„°
            if budget_filter:
                min_budget, max_budget = budget_filter
                if price < min_budget or price > max_budget:
                    continue
            
            # ìµœì¢… ì ìˆ˜ ê³„ì‚°
            avg_score = data['total_score'] / data['strategy_count']
            
            # ê°•í™” ì „ëµ ë³´ë„ˆìŠ¤
            enhancement_bonus = 0
            if 'enhanced' in data['scores']:
                enhancement_bonus += 0.15  # GPT ê°•í™” ë³´ë„ˆìŠ¤
            if 'few_shot' in data['scores']:
                enhancement_bonus += 0.1   # Few-shot ë³´ë„ˆìŠ¤
            
            # ë‹¤ì¤‘ ì „ëµ ë³´ë„ˆìŠ¤
            multi_bonus = min(data['strategy_count'] * 0.05, 0.15)
            
            final_score = min(avg_score + enhancement_bonus + multi_bonus, 1.0)
            
            # ê²°ê³¼ í¬ë§·íŒ…
            mattress_info = self._format_result(doc_id, data, final_score)
            final_results.append(mattress_info)
        
        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        final_results.sort(key=lambda x: x['similarity_score'], reverse=True)
        return final_results[:n_results]
    
    def _format_result(self, doc_id: str, data: Dict, final_score: float) -> Dict:
        """ê²°ê³¼ í¬ë§·íŒ…"""
        metadata = data['metadata']
        
        # featuresì™€ target_users ë³µì›
        features_text = metadata.get('features_text', '')
        features = [f.strip() for f in features_text.split(',') if f.strip()] if features_text else []
        
        target_users_text = metadata.get('target_users_text', '')
        target_users = [t.strip() for t in target_users_text.split(',') if t.strip()] if target_users_text else []
        
        return {
            'id': doc_id,
            'name': metadata.get('name', ''),
            'brand': metadata.get('brand', ''),
            'type': metadata.get('type', ''),
            'price': int(round(metadata.get('price', 0))),  # ì •ìˆ˜ë¡œ ë°˜ì˜¬ë¦¼
            'price_won': metadata.get('price_won', metadata.get('price', 0) * 10000),
            'similarity_score': final_score,
            'search_text': data['document'],
            'features': features,
            'target_users': target_users,
            'features_count': len(features),
            'target_users_count': len(target_users),
            'strategies_used': list(data['scores'].keys()),
            'gpt_enhanced': self.gpt_available,
            'enhanced_system': True
        }
    
    def get_mattress_by_id(self, mattress_id: str) -> Optional[Dict]:
        """IDë¡œ ë§¤íŠ¸ë¦¬ìŠ¤ ì¡°íšŒ"""
        if not self.data_loader:
            return None
        return self.data_loader.get_mattress_by_id(mattress_id)
    
    def get_system_status(self) -> Dict:
        """ì‹œìŠ¤í…œ ìƒíƒœ"""
        chroma_info = self.chroma_manager.get_collection_info()
        
        return {
            'initialized': self.is_initialized,
            'embedding_model': self.embedding_manager.model_name,
            'embedding_device': self.embedding_manager.device,
            'gpt_available': self.gpt_available,
            'chroma_collection': chroma_info,
            'enhancement_features': {
                'gpt_dynamic_synonyms': self.gpt_available,
                'few_shot_expansion': True,
                'multi_strategy_search': True,
                'weighted_scoring': True
            }
        }


# í¸ì˜ í•¨ìˆ˜
def setup_enhanced_rag_system(data_path: Optional[str] = None, reset_db: bool = False,
                             model_name: str = None, openai_api_key: str = None) -> Tuple[EnhancedMattressRAGSystem, bool]:
    """Enhanced RAG ì‹œìŠ¤í…œ ì„¤ì •"""
    try:
        # ë°ì´í„° ë¡œë”
        data_loader = MattressDataLoader(data_path)
        if not data_loader.load_mattress_data():
            return None, False
        
        # Enhanced RAG ì‹œìŠ¤í…œ
        rag_system = EnhancedMattressRAGSystem(
            model_name=model_name,
            openai_api_key=openai_api_key
        )
        
        if not rag_system.initialize_with_data(data_loader, reset_db):
            return rag_system, False
        
        logger.info("âœ… Enhanced RAG ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ")
        return rag_system, True
        
    except Exception as e:
        logger.error(f"Enhanced RAG ì„¤ì • ì‹¤íŒ¨: {e}")
        return None, False


# ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
KoreanMattressRAGSystem = EnhancedMattressRAGSystem
setup_korean_rag_system = setup_enhanced_rag_system


if __name__ == "__main__":
    print("ğŸš€ Enhanced ë§¤íŠ¸ë¦¬ìŠ¤ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    try:
        import os
        openai_key = os.getenv('OPENAI_API_KEY')
        
        rag_system, success = setup_enhanced_rag_system(
            openai_api_key=openai_key,
            reset_db=False
        )
        
        if success:
            status = rag_system.get_system_status()
            print(f"\nğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ:")
            print(f"  ì´ˆê¸°í™”: {status['initialized']}")
            print(f"  ì„ë² ë”© ëª¨ë¸: {status['embedding_model']}")
            print(f"  GPT ì‚¬ìš©: {status['gpt_available']}")
            print(f"  ì €ì¥ëœ ë¬¸ì„œ: {status['chroma_collection'].get('count', 0)}ê°œ")
            
            enhancement_features = status['enhancement_features']
            print(f"\nğŸš€ ê°•í™” ê¸°ëŠ¥:")
            for feature, enabled in enhancement_features.items():
                print(f"   {'âœ…' if enabled else 'âŒ'} {feature}")
            
            # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
            test_queries = [
                "í—ˆë¦¬ ë””ìŠ¤í¬ í™˜ììš© ë”±ë”±í•œ ë§¤íŠ¸ë¦¬ìŠ¤",
                "ë”ìœ„ ë§ì´ íƒ€ëŠ” ì‚¬ëŒìš© ì‹œì›í•œ ë§¤íŠ¸ë¦¬ìŠ¤", 
                "ì‹ í˜¼ë¶€ë¶€ í‚¹ì‚¬ì´ì¦ˆ ë©”ëª¨ë¦¬í¼",
                "50ë§Œì›ëŒ€ ê°€ì„±ë¹„ ì¢‹ì€ ë§¤íŠ¸ë¦¬ìŠ¤"
            ]
            
            print(f"\nğŸ” Enhanced ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
            for i, query in enumerate(test_queries, 1):
                print(f"\n{i}. '{query}'")
                
                results = rag_system.search_mattresses(query, n_results=3)
                
                if results:
                    for j, result in enumerate(results, 1):
                        strategies = result.get('strategies_used', [])
                        print(f"   {j}. {result['name']} ({result['brand']})")
                        print(f"      ìœ ì‚¬ë„: {result['similarity_score']:.3f}")
                        print(f"      ì „ëµ: {', '.join(strategies)}")
                        print(f"      GPTê°•í™”: {result.get('gpt_enhanced', False)}")
                else:
                    print("   ê²°ê³¼ ì—†ìŒ")
            
            print(f"\nâœ… Enhanced RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            
        else:
            print("âŒ Enhanced RAG ì‹œìŠ¤í…œ ì„¤ì • ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()