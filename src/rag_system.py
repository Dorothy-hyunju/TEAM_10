"""
RAG ì‹œìŠ¤í…œ - í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”© + ChromaDB
íŒŒì¼: src/rag_system.py

ì—­í• :
- í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”© ìƒì„±
- ChromaDB ë²¡í„° ê²€ìƒ‰
- ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„° ì „ì²˜ë¦¬ ë° ê²€ìƒ‰
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import chromadb
from chromadb.config import Settings
import numpy as np
from datetime import datetime
import time

# í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”©
try:
    from sentence_transformers import SentenceTransformer
    import torch
    HUGGINGFACE_AVAILABLE = True
except ImportError:
    HUGGINGFACE_AVAILABLE = False
    print("âš ï¸ í—ˆê¹…í˜ì´ìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤:")
    print("pip install sentence-transformers torch")

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
import sys
sys.path.append(str(Path(__file__).parent.parent))
from src.data_loader import MattressDataLoader

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class HuggingFaceEmbeddingManager:
    """í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”© ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, model_name: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"):
        """
        í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”© ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            model_name: ì‚¬ìš©í•  í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ëª… (í•œêµ­ì–´ ì§€ì›)
        """
        if not HUGGINGFACE_AVAILABLE:
            raise ImportError("sentence-transformersê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        try:
            # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
            
            # ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ ì§€ì› ëª¨ë¸ ìš°ì„ )
            try:
                self.model = SentenceTransformer(model_name, device=self.device)
                self.model_name = model_name
            except Exception:
                # í´ë°± ëª¨ë¸
                logger.warning("ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, í´ë°± ëª¨ë¸ ì‚¬ìš©")
                self.model = SentenceTransformer('all-MiniLM-L6-v2', device=self.device)
                self.model_name = 'all-MiniLM-L6-v2'
            
            # ì„ë² ë”© ìºì‹œ (ì„±ëŠ¥ í–¥ìƒ)
            self.embedding_cache = {}
            
            logger.info(f"í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”© ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
            logger.info(f"ëª¨ë¸: {self.model_name}")
            logger.info(f"ë””ë°”ì´ìŠ¤: {self.device}")
            
        except Exception as e:
            logger.error(f"í—ˆê¹…í˜ì´ìŠ¤ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def generate_embedding(self, text: str) -> List[float]:
        """
        ë‹¨ì¼ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ìƒì„±
        
        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
            
        Returns:
            List[float]: ì„ë² ë”© ë²¡í„°
        """
        # ìºì‹œ í™•ì¸
        if text in self.embedding_cache:
            return self.embedding_cache[text]
        
        try:
            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            if not text or not text.strip():
                text = "ë¹ˆ í…ìŠ¤íŠ¸"
            
            # ì„ë² ë”© ìƒì„±
            embedding = self.model.encode(text, convert_to_tensor=False)
            
            # numpy arrayë¥¼ listë¡œ ë³€í™˜
            if isinstance(embedding, np.ndarray):
                embedding = embedding.tolist()
            
            # ìºì‹œ ì €ì¥
            self.embedding_cache[text] = embedding
            
            logger.debug(f"ì„ë² ë”© ìƒì„± ì™„ë£Œ: {text[:50]}... (ì°¨ì›: {len(embedding)})")
            return embedding
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ì°¨ì›ì˜ ë”ë¯¸ ì„ë² ë”© ë°˜í™˜
            default_dim = 384  # ëŒ€ë¶€ë¶„ì˜ sentence-transformers ëª¨ë¸ ê¸°ë³¸ ì°¨ì›
            return [0.0] * default_dim
    
    def generate_embeddings_batch(self, texts: List[str], batch_size: int = 32) -> List[List[float]]:
        """
        ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì„ ë°°ì¹˜ë¡œ ìƒì„±
        
        Args:
            texts: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            batch_size: ë°°ì¹˜ í¬ê¸°
            
        Returns:
            List[List[float]]: ì„ë² ë”© ë²¡í„°ë“¤
        """
        if not texts:
            return []
        
        embeddings = []
        
        # ë¹ˆ í…ìŠ¤íŠ¸ ì²˜ë¦¬
        processed_texts = []
        for text in texts:
            if not text or not text.strip():
                processed_texts.append("ë¹ˆ í…ìŠ¤íŠ¸")
            else:
                processed_texts.append(text)
        
        try:
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            for i in range(0, len(processed_texts), batch_size):
                batch_texts = processed_texts[i:i + batch_size]
                
                # ìºì‹œ í™•ì¸ ë° ìƒˆ í…ìŠ¤íŠ¸ ë¶„ë¦¬
                batch_embeddings = []
                new_texts = []
                cache_map = {}
                
                for j, text in enumerate(batch_texts):
                    if text in self.embedding_cache:
                        batch_embeddings.append(self.embedding_cache[text])
                    else:
                        new_texts.append(text)
                        cache_map[len(new_texts) - 1] = j
                        batch_embeddings.append(None)  # ìë¦¬ í‘œì‹œ
                
                # ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë“¤ ì„ë² ë”© ìƒì„±
                if new_texts:
                    try:
                        new_embeddings = self.model.encode(
                            new_texts, 
                            convert_to_tensor=False, 
                            batch_size=min(len(new_texts), batch_size)
                        )
                        
                        # numpy arrayë¥¼ listë¡œ ë³€í™˜
                        if isinstance(new_embeddings, np.ndarray):
                            if len(new_embeddings.shape) == 1:  # ë‹¨ì¼ ì„ë² ë”©ì¸ ê²½ìš°
                                new_embeddings = [new_embeddings.tolist()]
                            else:
                                new_embeddings = new_embeddings.tolist()
                        
                        # ìºì‹œ ì €ì¥ ë° ê²°ê³¼ ì—…ë°ì´íŠ¸
                        for new_idx, (text, embedding) in enumerate(zip(new_texts, new_embeddings)):
                            self.embedding_cache[text] = embedding
                            batch_idx = cache_map[new_idx]
                            batch_embeddings[batch_idx] = embedding
                            
                    except Exception as e:
                        logger.error(f"ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
                        # ê°œë³„ ìƒì„±ìœ¼ë¡œ í´ë°±
                        for new_idx, text in enumerate(new_texts):
                            embedding = self.generate_embedding(text)
                            batch_idx = cache_map[new_idx]
                            batch_embeddings[batch_idx] = embedding
                
                embeddings.extend(batch_embeddings)
                logger.info(f"ë°°ì¹˜ ì„ë² ë”© ì™„ë£Œ: {i + len(batch_texts)}/{len(texts)}")
            
            return embeddings
            
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            # ì™„ì „ í´ë°±: ê°œë³„ ìƒì„±
            return [self.generate_embedding(text) for text in processed_texts]

class ChromaDBManager:
    """ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, persist_directory: str = "./chroma_db"):
        """
        ChromaDB ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            persist_directory: ChromaDB ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.persist_directory = Path(persist_directory)
        self.persist_directory.mkdir(exist_ok=True)
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = chromadb.PersistentClient(path=str(self.persist_directory))
        
        # ì»¬ë ‰ì…˜ ì´ë¦„
        self.collection_name = "mattress_collection_v2"
        self.collection = None
        
        logger.info(f"ChromaDB ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ (ì €ì¥ ìœ„ì¹˜: {self.persist_directory})")
    
    def create_collection(self, reset: bool = False) -> bool:
        """
        ë§¤íŠ¸ë¦¬ìŠ¤ ì»¬ë ‰ì…˜ ìƒì„±
        
        Args:
            reset: ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„± ì—¬ë¶€
            
        Returns:
            bool: ìƒì„± ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ (reset=Trueì¸ ê²½ìš°)
            if reset:
                try:
                    self.client.delete_collection(self.collection_name)
                    logger.info("ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ ì™„ë£Œ")
                except:
                    pass
            
            # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
            self.collection = self.client.get_or_create_collection(
                name=self.collection_name,
                metadata={"description": "ë§¤íŠ¸ë¦¬ìŠ¤ ì •ë³´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ (í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”©)"}
            )
            
            logger.info(f"ì»¬ë ‰ì…˜ '{self.collection_name}' ì¤€ë¹„ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def add_documents(self, documents: List[str], embeddings: List[List[float]], 
                     metadatas: List[Dict], ids: List[str]) -> bool:
        """
        ë¬¸ì„œë“¤ì„ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€
        
        Args:
            documents: ë¬¸ì„œ í…ìŠ¤íŠ¸ë“¤
            embeddings: ì„ë² ë”© ë²¡í„°ë“¤
            metadatas: ë©”íƒ€ë°ì´í„°ë“¤
            ids: ë¬¸ì„œ IDë“¤
            
        Returns:
            bool: ì¶”ê°€ ì„±ê³µ ì—¬ë¶€
        """
        if not self.collection:
            logger.error("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return False
        
        try:
            # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
            if len(documents) != len(embeddings) or len(documents) != len(metadatas) or len(documents) != len(ids):
                logger.error("ë¬¸ì„œ, ì„ë² ë”©, ë©”íƒ€ë°ì´í„°, ID ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                return False
            
            self.collection.add(
                documents=documents,
                embeddings=embeddings,
                metadatas=metadatas,
                ids=ids
            )
            
            logger.info(f"ë¬¸ì„œ {len(documents)}ê°œ ì¶”ê°€ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False
    
    def search_similar(self, query_embedding: List[float], n_results: int = 5) -> Dict:
        """
        ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
        
        Args:
            query_embedding: ì¿¼ë¦¬ ì„ë² ë”©
            n_results: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            Dict: ê²€ìƒ‰ ê²°ê³¼
        """
        if not self.collection:
            logger.error("ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return {}
        
        try:
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results
            )
            
            return results
            
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_collection_info(self) -> Dict:
        """ì»¬ë ‰ì…˜ ì •ë³´ ë°˜í™˜"""
        if not self.collection:
            return {"error": "ì»¬ë ‰ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}
        
        try:
            count = self.collection.count()
            return {
                "name": self.collection_name,
                "count": count,
                "persist_directory": str(self.persist_directory)
            }
        except Exception as e:
            return {"error": str(e)}

class MattressRAGSystem:
    """ë§¤íŠ¸ë¦¬ìŠ¤ RAG ê²€ìƒ‰ ì‹œìŠ¤í…œ (ì„ë² ë”© + ë²¡í„° ê²€ìƒ‰ ì „ë‹´)"""
    
    def __init__(self, persist_directory: str = "./chroma_db"):
        """
        ë§¤íŠ¸ë¦¬ìŠ¤ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            persist_directory: ChromaDB ì €ì¥ ë””ë ‰í† ë¦¬
        """
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.embedding_manager = HuggingFaceEmbeddingManager()
        self.chroma_manager = ChromaDBManager(persist_directory)
        self.data_loader = None
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.is_initialized = False
        
        logger.info("ë§¤íŠ¸ë¦¬ìŠ¤ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"ì„ë² ë”©: í—ˆê¹…í˜ì´ìŠ¤ ({self.embedding_manager.model_name})")
    
    def initialize_with_data(self, data_loader: MattressDataLoader, reset_db: bool = False) -> bool:
        """
        ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„°ë¡œ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            data_loader: ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„° ë¡œë”
            reset_db: ë°ì´í„°ë² ì´ìŠ¤ ë¦¬ì…‹ ì—¬ë¶€
            
        Returns:
            bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        try:
            logger.info("RAG ì‹œìŠ¤í…œ ë°ì´í„° ì´ˆê¸°í™” ì‹œì‘")
            
            # ë°ì´í„° ë¡œë” ì„¤ì •
            self.data_loader = data_loader
            
            # ChromaDB ì»¬ë ‰ì…˜ ìƒì„±
            if not self.chroma_manager.create_collection(reset=reset_db):
                return False
            
            # ê¸°ì¡´ ë°ì´í„° í™•ì¸
            collection_info = self.chroma_manager.get_collection_info()
            if collection_info.get("count", 0) > 0 and not reset_db:
                logger.info(f"ê¸°ì¡´ ë°ì´í„° ë°œê²¬: {collection_info['count']}ê°œ ë¬¸ì„œ")
                self.is_initialized = True
                return True
            
            # RAGìš© ë°ì´í„° ì „ì²˜ë¦¬
            rag_data = data_loader.preprocess_for_rag()
            if not rag_data:
                logger.error("RAGìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            # í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            documents = [item['search_text'] for item in rag_data]
            metadatas = [item['metadata'] for item in rag_data]
            ids = [item['id'] for item in rag_data]
            
            logger.info(f"í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”© ìƒì„± ì‹œì‘: {len(documents)}ê°œ ë¬¸ì„œ")
            
            # í—ˆê¹…í˜ì´ìŠ¤ë¡œ ì„ë² ë”© ìƒì„±
            embeddings = self.embedding_manager.generate_embeddings_batch(documents)
            
            # ChromaDBì— ì €ì¥
            if self.chroma_manager.add_documents(documents, embeddings, metadatas, ids):
                self.is_initialized = True
                logger.info("âœ… RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
                return True
            else:
                return False
                
        except Exception as e:
            logger.error(f"RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def search_mattresses(self, query: str, n_results: int = 5) -> List[Dict]:
        """
        ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰ (í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”© ì‚¬ìš©)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            n_results: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            List[Dict]: ê²€ìƒ‰ëœ ë§¤íŠ¸ë¦¬ìŠ¤ ì •ë³´ë“¤
        """
        if not self.is_initialized:
            logger.error("RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return []
        
        try:
            # í—ˆê¹…í˜ì´ìŠ¤ë¡œ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.embedding_manager.generate_embedding(query)
            
            # ChromaDBì—ì„œ ìœ ì‚¬í•œ ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰
            search_results = self.chroma_manager.search_similar(query_embedding, n_results)
            
            if not search_results or not search_results.get('documents'):
                logger.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
                return []
            
            # ê²°ê³¼ í¬ë§·íŒ…
            mattresses = []
            for i in range(len(search_results['documents'][0])):
                # ë©”íƒ€ë°ì´í„°ì—ì„œ ì•ˆì „í•˜ê²Œ ê°’ ì¶”ì¶œ
                metadata = search_results['metadatas'][0][i]
                
                # ë¬¸ìì—´ë¡œ ì €ì¥ëœ featuresì™€ target_usersë¥¼ ë‹¤ì‹œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                features_text = metadata.get('features_text', '')
                features = [f.strip() for f in features_text.split(',') if f.strip()] if features_text else []
                
                target_users_text = metadata.get('target_users_text', '')
                target_users = [t.strip() for t in target_users_text.split(',') if t.strip()] if target_users_text else []
                
                mattress_info = {
                    'id': search_results['ids'][0][i],
                    'name': metadata.get('name', ''),
                    'brand': metadata.get('brand', ''),
                    'type': metadata.get('type', ''),
                    'price': metadata.get('price', 0),
                    'similarity_score': 1 - search_results['distances'][0][i],  # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                    'search_text': search_results['documents'][0][i],
                    'features': features,
                    'target_users': target_users,
                    'features_count': metadata.get('features_count', 0),
                    'target_users_count': metadata.get('target_users_count', 0)
                }
                mattresses.append(mattress_info)
            
            logger.info(f"ê²€ìƒ‰ ì™„ë£Œ: {len(mattresses)}ê°œ ë§¤íŠ¸ë¦¬ìŠ¤ ë°œê²¬")
            return mattresses
            
        except Exception as e:
            logger.error(f"ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def get_mattress_by_id(self, mattress_id: str) -> Optional[Dict]:
        """IDë¡œ íŠ¹ì • ë§¤íŠ¸ë¦¬ìŠ¤ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        if not self.data_loader:
            return None
        return self.data_loader.get_mattress_by_id(mattress_id)
    
    def get_system_status(self) -> Dict:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        chroma_info = self.chroma_manager.get_collection_info()
        
        return {
            'initialized': self.is_initialized,
            'embedding_model': self.embedding_manager.model_name,
            'embedding_device': self.embedding_manager.device,
            'embedding_cache_size': len(self.embedding_manager.embedding_cache),
            'chroma_collection': chroma_info
        }

# í¸ì˜ í•¨ìˆ˜
def setup_rag_system(data_path: Optional[str] = None, reset_db: bool = False) -> Tuple[MattressRAGSystem, bool]:
    """
    RAG ì‹œìŠ¤í…œ ì„¤ì • í¸ì˜ í•¨ìˆ˜
    
    Args:
        data_path: ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        reset_db: ë°ì´í„°ë² ì´ìŠ¤ ë¦¬ì…‹ ì—¬ë¶€
        
    Returns:
        Tuple[MattressRAGSystem, bool]: (RAG ì‹œìŠ¤í…œ, ì„±ê³µ ì—¬ë¶€)
    """
    try:
        # í—ˆê¹…í˜ì´ìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™•ì¸
        if not HUGGINGFACE_AVAILABLE:
            logger.error("í—ˆê¹…í˜ì´ìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            print("í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:")
            print("pip install sentence-transformers torch")
            return None, False
        
        # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
        data_loader = MattressDataLoader(data_path)
        if not data_loader.load_mattress_data():
            logger.error("ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            return None, False
        
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        rag_system = MattressRAGSystem()
        if not rag_system.initialize_with_data(data_loader, reset_db):
            logger.error("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
            return rag_system, False
        
        logger.info("âœ… RAG ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ")
        return rag_system, True
        
    except Exception as e:
        logger.error(f"RAG ì‹œìŠ¤í…œ ì„¤ì • ì‹¤íŒ¨: {e}")
        return None, False

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸ” ë§¤íŠ¸ë¦¬ìŠ¤ RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # RAG ì‹œìŠ¤í…œ ì„¤ì •
        rag_system, success = setup_rag_system(reset_db=False)
        
        if success:
            # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
            status = rag_system.get_system_status()
            print(f"\nğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ:")
            print(f"  ì´ˆê¸°í™”: {status['initialized']}")
            print(f"  ì„ë² ë”© ëª¨ë¸: {status['embedding_model']}")
            print(f"  ë””ë°”ì´ìŠ¤: {status['embedding_device']}")
            print(f"  ì €ì¥ëœ ë¬¸ì„œ: {status['chroma_collection'].get('count', 0)}ê°œ")
            
            # í…ŒìŠ¤íŠ¸ ê²€ìƒ‰
            test_queries = [
                "í—ˆë¦¬ í†µì¦ì„ ìœ„í•œ ë§¤íŠ¸ë¦¬ìŠ¤",
                "ì‹œì›í•œ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œ",
                "50ë§Œì› ì´í•˜ ë§¤íŠ¸ë¦¬ìŠ¤"
            ]
            
            print(f"\nğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸:")
            for i, query in enumerate(test_queries, 1):
                print(f"\n{i}. ì¿¼ë¦¬: '{query}'")
                
                results = rag_system.search_mattresses(query, n_results=3)
                
                if results:
                    print(f"   ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ")
                    for j, result in enumerate(results, 1):
                        print(f"   {j}. {result['name']} (ìœ ì‚¬ë„: {result['similarity_score']:.3f})")
                else:
                    print("   ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            
            print(f"\nâœ… RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
            
        else:
            print(f"\nâŒ RAG ì‹œìŠ¤í…œ ì„¤ì • ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        print(f"ğŸ’¡ í•„ìš”í•œ ì„¤ì¹˜: pip install sentence-transformers torch")