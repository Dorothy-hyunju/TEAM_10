"""
AI ì—ì´ì „íŠ¸ - Enhanced RAG + GPT ë™ì˜ì–´ + Few-shot ê°•í™” ë²„ì „
íŒŒì¼: src/ai_agent.py

ì£¼ìš” ê°œì„ :
1. Enhanced RAG ì‹œìŠ¤í…œ í†µí•©
2. GPT ê¸°ë°˜ ë™ì  ë™ì˜ì–´ í™œìš©
3. Few-shot í•™ìŠµ ê°•í™”
4. ìœ ì‚¬ë„ ì ìˆ˜ ê·¹ëŒ€í™”
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple, Union
from datetime import datetime
import time
import re

# OpenAI í´ë¼ì´ì–¸íŠ¸
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install openai")

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
import sys
sys.path.append(str(Path(__file__).parent.parent))

try:
    from src.rag_system import EnhancedMattressRAGSystem, setup_enhanced_rag_system
except ImportError:
    print("âš ï¸ enhanced rag_system ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    raise

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SmartRelevanceChecker:
    """íš¨ìœ¨ì ì¸ ë§¤íŠ¸ë¦¬ìŠ¤ ê´€ë ¨ì„± ì²´í¬ (í‚¤ì›Œë“œ + GPT)"""
    
    def __init__(self, openai_client=None):
        self.client = openai_client
        self.cache = {}  # ê²°ê³¼ ìºì‹œë¡œ ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€
        
        # í™•ì‹¤íˆ ê´€ë ¨ëœ í‚¤ì›Œë“œ (ì¦‰ì‹œ í†µê³¼) - ë§¤íŠ¸ë¦¬ìŠ¤/ì¹¨ëŒ€/ìˆ˜ë©´ë§Œ
        self.certain_keywords = {
            'ë§¤íŠ¸ë¦¬ìŠ¤', 'ì¹¨ëŒ€', 'ë² ë“œ', 'ì ìë¦¬', 'ìˆ˜ë©´', 'ì ', 'ìëŠ”',
            'ë©”ëª¨ë¦¬í¼', 'ë¼í…ìŠ¤', 'ìŠ¤í”„ë§', 'ë³¸ë„¬', 'í¬ì¼“ìŠ¤í”„ë§',
            'ì‹±ê¸€', 'ë”ë¸”', 'í€¸', 'í‚¹ì‚¬ì´ì¦ˆ', 'ì¹¨ëŒ€ì‚¬ì´ì¦ˆ',
            'ë² ê°œ', 'ì´ë¶ˆ', 'ì¹¨êµ¬', 'ì¹¨ì‹¤ìš©í’ˆ', 'ìˆ˜ë©´ìš©í’ˆ'
        }
        
        # í™•ì‹¤íˆ ë¬´ê´€í•œ í‚¤ì›Œë“œ (ì¦‰ì‹œ ì°¨ë‹¨)
        self.irrelevant_keywords = {
            # ìŒì‹ ê´€ë ¨
            'ë°°ê³ íŒŒ', 'ë°¥', 'ìŒì‹', 'ë¨¹ëŠ”', 'ì‹ì‚¬', 'ìš”ë¦¬', 'ë§›ìˆëŠ”',
            # ë‚ ì”¨ ê´€ë ¨
            'ë‚ ì”¨', 'ë¹„', 'ëˆˆ', 'ë”ìœ„', 'ì¶”ìœ„', 'ì˜¨ë„', 'ê¸°ì˜¨',
            # ì—”í„°í…Œì¸ë¨¼íŠ¸
            'ì˜í™”', 'ë“œë¼ë§ˆ', 'ê²Œì„', 'ì±…', 'ì†Œì„¤', 'ë§Œí™”',
            'ì¶•êµ¬', 'ì•¼êµ¬', 'ë†êµ¬', 'í—¬ìŠ¤', 'ë‹¬ë¦¬ê¸°', 'ìš´ë™',
            # ë‹¤ë¥¸ ê°€êµ¬ë“¤ (ë§¤íŠ¸ë¦¬ìŠ¤/ì¹¨ëŒ€ ì œì™¸)
            'ì„œëì¥', 'ì˜·ì¥', 'ë¶™ë°•ì´ì¥', 'í™”ì¥ëŒ€', 'ì±…ìƒ', 'ì˜ì',
            'ì†ŒíŒŒ', 'ì‡¼íŒŒ', 'í…Œì´ë¸”', 'ì‹íƒ', 'ë‹¤ì´ë‹í…Œì´ë¸”',
            'ì„ ë°˜', 'ì±…ì¥', 'ì§„ì—´ì¥', 'ìˆ˜ë‚©ì¥', 'ì‹ ë°œì¥',
            'í–‰ê±°', 'ì˜·ê±¸ì´', 'ê±°ìš¸', 'ìŠ¤íƒ ë“œ', 'ì¡°ëª…',
            'ì»¤íŠ¼', 'ë¸”ë¼ì¸ë“œ', 'ì¹´í«', 'ëŸ¬ê·¸', 'ë§¤íŠ¸',
            'ì¿ ì…˜', 'ë°©ì„', 'ë“±ë°›ì´', 'íŒ”ê±¸ì´',
            # ê°€ì „ì œí’ˆ
            'ëƒ‰ì¥ê³ ', 'ì„¸íƒê¸°', 'ì—ì–´ì»¨', 'í…”ë ˆë¹„ì „', 'tv',
            'ì „ìë ˆì¸ì§€', 'ì˜¤ë¸', 'ì²­ì†Œê¸°', 'ê³µê¸°ì²­ì •ê¸°',
            # ê¸°íƒ€
            'ì¼', 'ì§ì¥', 'íšŒì‚¬', 'ì—…ë¬´', 'íšŒì˜', 'ì¶œê·¼',
            'ì¹œêµ¬', 'ì—°ì• ', 'ë°ì´íŠ¸', 'ë§Œë‚¨', 'í—¤ì–´ì§',
            'ì—¬í–‰', 'íœ´ê°€', 'ë†€ëŸ¬', 'êµ¬ê²½', 'ê´€ê´‘',
            'í•™êµ', 'ê³µë¶€', 'ì‹œí—˜', 'ìˆ™ì œ', 'ê³¼ì œ',
            'ëˆ', 'íˆ¬ì', 'ì£¼ì‹', 'ë¶€ë™ì‚°', 'ëŒ€ì¶œ'
        }
        
        # ì• ë§¤í•œ í‚¤ì›Œë“œ (GPT íŒë‹¨ í•„ìš”) - ìˆ˜ë©´ê³¼ ê´€ë ¨ ê°€ëŠ¥ì„±ì´ ìˆëŠ” ê²ƒë“¤ë§Œ
        self.ambiguous_keywords = {
            'í—ˆë¦¬', 'ëª©', 'ì–´ê¹¨', 'í†µì¦', 'ì•„í”ˆ', 'í¸ì•ˆ', 'ë”±ë”±', 'ë¶€ë“œëŸ¬ìš´',
            'ê°€ê²©', 'ì¶”ì²œ', 'ë¸Œëœë“œ', 'ì¢‹ì€', 'í¸ì•ˆí•œ', 'ì‹œì›í•œ', 'ë”°ëœ»í•œ',
            'ë†’ì€', 'ë‚®ì€', 'í¬ê¸°', 'ì‚¬ì´ì¦ˆ', 'ë¬´ê±°ìš´', 'ê°€ë²¼ìš´'
        }
    
    def check_relevance(self, query: str) -> Dict[str, Any]:
        """ë‹¨ê³„ë³„ ê´€ë ¨ì„± ì²´í¬"""
        query_clean = query.lower().strip()
        
        # ìºì‹œ í™•ì¸
        if query_clean in self.cache:
            return self.cache[query_clean]
        
        # 1ë‹¨ê³„: ë„ˆë¬´ ì§§ì€ ì§ˆë¬¸
        if len(query.strip()) < 3:
            result = {
                'is_relevant': False,
                'reason': 'ì§ˆë¬¸ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤',
                'confidence': 0.95,
                'method': 'length_check'
            }
            self.cache[query_clean] = result
            return result
        
        # 2ë‹¨ê³„: í™•ì‹¤íˆ ê´€ë ¨ëœ í‚¤ì›Œë“œ ì²´í¬
        if any(keyword in query_clean for keyword in self.certain_keywords):
            result = {
                'is_relevant': True,
                'reason': 'ë§¤íŠ¸ë¦¬ìŠ¤ ê´€ë ¨ í‚¤ì›Œë“œ ë°œê²¬',
                'confidence': 0.95,
                'method': 'certain_keywords'
            }
            self.cache[query_clean] = result
            return result
        
        # 3ë‹¨ê³„: í™•ì‹¤íˆ ë¬´ê´€í•œ í‚¤ì›Œë“œ ì²´í¬
        if any(keyword in query_clean for keyword in self.irrelevant_keywords):
            result = {
                'is_relevant': False,
                'reason': 'ë§¤íŠ¸ë¦¬ìŠ¤ì™€ ë¬´ê´€í•œ í‚¤ì›Œë“œ ë°œê²¬',
                'confidence': 0.90,
                'method': 'irrelevant_keywords'
            }
            self.cache[query_clean] = result
            return result
        
        # 4ë‹¨ê³„: ì• ë§¤í•œ ê²½ìš°ë§Œ GPT í˜¸ì¶œ (ë¹„ìš© ì ˆì•½)
        has_ambiguous = any(keyword in query_clean for keyword in self.ambiguous_keywords)
        
        if has_ambiguous and self.client:
            result = self._gpt_relevance_check(query)
            result['method'] = 'gpt_check'
        else:
            # GPT ì—†ê±°ë‚˜ ì• ë§¤í•˜ì§€ ì•Šì€ ê²½ìš° â†’ ë³´ìˆ˜ì ìœ¼ë¡œ ê´€ë ¨ ì—†ìŒ ì²˜ë¦¬
            result = {
                'is_relevant': False,
                'reason': 'ë§¤íŠ¸ë¦¬ìŠ¤ ê´€ë ¨ì„±ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
                'confidence': 0.70,
                'method': 'conservative_fallback'
            }
        
        self.cache[query_clean] = result
        return result
    
    def _gpt_relevance_check(self, query: str) -> Dict[str, Any]:
        """GPTë¡œ ê´€ë ¨ì„± ì²´í¬ (ìµœì†Œ ë¹„ìš©)"""
        try:
            system_prompt = """ë§¤íŠ¸ë¦¬ìŠ¤/ì¹¨ëŒ€/ìˆ˜ë©´ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

í—ˆìš©ë˜ëŠ” ì§ˆë¬¸:
- ë§¤íŠ¸ë¦¬ìŠ¤, ì¹¨ëŒ€, ìˆ˜ë©´, ì ìë¦¬ ê´€ë ¨
- ì¹¨êµ¬ë¥˜ (ë² ê°œ, ì´ë¶ˆ, ë§¤íŠ¸ë¦¬ìŠ¤íŒ¨ë“œ ë“±)
- ìˆ˜ë©´ ê±´ê°• (í—ˆë¦¬, ëª© í†µì¦ ë“±ê³¼ ë§¤íŠ¸ë¦¬ìŠ¤ ì—°ê´€)

ì°¨ë‹¨ë˜ëŠ” ì§ˆë¬¸:
- ë‹¤ë¥¸ ê°€êµ¬ (ì„œëì¥, ì†ŒíŒŒ, ì±…ìƒ, ì˜ì ë“±)
- ê°€ì „ì œí’ˆ (ëƒ‰ì¥ê³ , TV, ì—ì–´ì»¨ ë“±)
- ë§¤íŠ¸ë¦¬ìŠ¤ì™€ ë¬´ê´€í•œ ëª¨ë“  ì§ˆë¬¸

ì˜ˆì‹œ:
- "í—ˆë¦¬ ì•„í”ˆ ì‚¬ëŒ ë§¤íŠ¸ë¦¬ìŠ¤" â†’ ê´€ë ¨ìˆìŒ
- "ë”±ë”±í•œ ì¹¨ëŒ€ ì¶”ì²œ" â†’ ê´€ë ¨ìˆìŒ  
- "ì„œëì¥ ì¶”ì²œí•´ì£¼ì„¸ìš”" â†’ ê´€ë ¨ì—†ìŒ
- "ì†ŒíŒŒ ì–´ë–¤ê²Œ ì¢‹ì•„ìš”?" â†’ ê´€ë ¨ì—†ìŒ
- "ë°°ê³ íŒŒ" â†’ ê´€ë ¨ì—†ìŒ
- "í—ˆë¦¬ ì•„íŒŒ" â†’ ì• ë§¤ (ë§¤íŠ¸ë¦¬ìŠ¤ì™€ ì—°ê´€ ê°€ëŠ¥ì„± í™•ì¸ í•„ìš”)

í˜•ì‹: {"relevant": true/false, "reason": "ì´ìœ "}"""
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ì§ˆë¬¸: '{query}'"}
                ],
                max_tokens=50,  # ë§¤ìš° ì§§ê²Œ ì œí•œ (ë¹„ìš© ì ˆì•½)
                temperature=0.1
            )
            
            content = response.choices[0].message.content.strip()
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                if "```json" in content:
                    start = content.find("```json") + 7
                    end = content.find("```", start)
                    content = content[start:end].strip()
                
                result_data = json.loads(content)
                
                return {
                    'is_relevant': result_data.get('relevant', False),
                    'reason': result_data.get('reason', 'GPT íŒë‹¨'),
                    'confidence': 0.85
                }
                
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ë‹¨ìˆœ í‚¤ì›Œë“œ ê¸°ë°˜ íŒë‹¨
                is_relevant = 'true' in content.lower() or 'relevant' in content.lower()
                return {
                    'is_relevant': is_relevant,
                    'reason': 'GPT ì‘ë‹µ ê¸°ë°˜ íŒë‹¨',
                    'confidence': 0.75
                }
                
        except Exception as e:
            logger.error(f"GPT ê´€ë ¨ì„± ì²´í¬ ì‹¤íŒ¨: {e}")
            return {
                'is_relevant': False,
                'reason': 'GPT ì²´í¬ ì‹¤íŒ¨ë¡œ ì•ˆì „í•˜ê²Œ ë¬´ê´€ ì²˜ë¦¬',
                'confidence': 0.60
            }
    
    def get_irrelevant_response(self, query: str, reason: str) -> str:
        """ë¬´ê´€í•œ ì§ˆë¬¸ì— ëŒ€í•œ ì•ˆë‚´ ë©”ì‹œì§€"""
        
        # ê°€êµ¬ ê´€ë ¨ ì§ˆë¬¸ ê°ì§€
        furniture_keywords = {
            'ì„œëì¥', 'ì˜·ì¥', 'í™”ì¥ëŒ€', 'ì±…ìƒ', 'ì˜ì', 'ì†ŒíŒŒ', 'ì‡¼íŒŒ', 
            'í…Œì´ë¸”', 'ì‹íƒ', 'ì„ ë°˜', 'ì±…ì¥', 'ìˆ˜ë‚©ì¥'
        }
        
        query_lower = query.lower()
        is_furniture_query = any(keyword in query_lower for keyword in furniture_keywords)
        
        if is_furniture_query:
            detected_furniture = [kw for kw in furniture_keywords if kw in query_lower]
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” ë§¤íŠ¸ë¦¬ìŠ¤ ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. {', '.join(detected_furniture)}ì™€ ê°™ì€ ë‹¤ë¥¸ ê°€êµ¬ëŠ” ì¶”ì²œë“œë¦´ ìˆ˜ ì—†ì–´ìš”.\n\në§¤íŠ¸ë¦¬ìŠ¤, ì¹¨ëŒ€, ë˜ëŠ” ìˆ˜ë©´ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ˜Š"
        
        responses = {
            'ì§ˆë¬¸ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤': "ì§ˆë¬¸ì„ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ í•´ì£¼ì„¸ìš”. ë§¤íŠ¸ë¦¬ìŠ¤ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ìì„¸íˆ ë§ì”€í•´ì£¼ì‹œë©´ ë„ì›€ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ğŸ˜Š",
            'ë§¤íŠ¸ë¦¬ìŠ¤ì™€ ë¬´ê´€í•œ í‚¤ì›Œë“œ ë°œê²¬': "ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” ë§¤íŠ¸ë¦¬ìŠ¤ ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ë§¤íŠ¸ë¦¬ìŠ¤, ì¹¨ëŒ€, ìˆ˜ë©´ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ë§Œ ë„ì›€ë“œë¦´ ìˆ˜ ìˆì–´ìš”.\n\nì˜ˆë¥¼ ë“¤ì–´ 'í—ˆë¦¬ì— ì¢‹ì€ ë§¤íŠ¸ë¦¬ìŠ¤', 'ì˜ˆì‚° ë‚´ ì¶”ì²œ ë§¤íŠ¸ë¦¬ìŠ¤' ê°™ì€ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”! ğŸ˜Š",
            'GPT ì²´í¬ ì‹¤íŒ¨ë¡œ ì•ˆì „í•˜ê²Œ ë¬´ê´€ ì²˜ë¦¬': "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì •í™•íˆ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë§¤íŠ¸ë¦¬ìŠ¤ë‚˜ ìˆ˜ë©´ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì„ ëª…í™•í•˜ê²Œ í•´ì£¼ì‹œë©´ ë„ì›€ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ğŸ˜Š",
            'ë§¤íŠ¸ë¦¬ìŠ¤ ê´€ë ¨ì„±ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤': "ì£„ì†¡í•©ë‹ˆë‹¤. ë§¤íŠ¸ë¦¬ìŠ¤ë‚˜ ìˆ˜ë©´ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì¸ì§€ í™•ì‹¤í•˜ì§€ ì•Šë„¤ìš”. ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ ì§ˆë¬¸í•´ì£¼ì‹œë©´ ë„ì›€ë“œë¦¬ê² ìŠµë‹ˆë‹¤!\n\nì˜ˆ: 'ë”±ë”±í•œ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”', '50ë§Œì›ëŒ€ ê°€ì„±ë¹„ ë§¤íŠ¸ë¦¬ìŠ¤ ìˆë‚˜ìš”?' ğŸ˜Š"
        }
        
        return responses.get(reason, "ì£„ì†¡í•©ë‹ˆë‹¤. ë§¤íŠ¸ë¦¬ìŠ¤ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë„ì›€ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ğŸ˜Š")

class EnhancedQueryProcessor:
    """Few-shot ê°•í™” ì¿¼ë¦¬ í”„ë¡œì„¸ì„œ"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-3.5-turbo"):
        self.client = None
        self.model = model
        
        if not OPENAI_AVAILABLE:
            logger.warning("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return
        
        api_key = api_key or os.getenv('OPENAI_API_KEY')
        if not api_key:
            logger.warning("OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        try:
            self.client = OpenAI(api_key=api_key)
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            test_response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "í…ŒìŠ¤íŠ¸"}],
                max_tokens=5
            )
            
            logger.info(f"Enhanced ì¿¼ë¦¬ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {self.model})")
            
        except Exception as e:
            logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.client = None
    
    def expand_query_with_gpt_synonyms(self, user_query: str) -> Dict[str, Any]:
        """GPT ë™ì˜ì–´ ê¸°ë°˜ ì¿¼ë¦¬ í™•ì¥"""
        if not self.client:
            return self._fallback_query_expansion(user_query)
        
        try:
            system_prompt = """
    ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰ ì „ë¬¸ê°€ë¡œì„œ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ê³  í™•ì¥í•˜ì„¸ìš”.

    Few-shot ì˜ˆì‹œ:
    ì…ë ¥: "í—ˆë¦¬ ì•„í”ˆ ì‚¬ëŒ ë§¤íŠ¸ë¦¬ìŠ¤"
    ì¶œë ¥: {
    "main_keywords": ["í—ˆë¦¬", "ì•„í”ˆ", "ë§¤íŠ¸ë¦¬ìŠ¤"],
    "gpt_synonyms": {
        "í—ˆë¦¬": ["ìš”ì¶”", "ì²™ì¶”", "ë“±", "í—ˆë¦¬í†µì¦", "ìš”í†µ"],
        "ì•„í”ˆ": ["í†µì¦", "ë¬¸ì œ", "ë¶ˆí¸", "ì§ˆí™˜", "ì•„í””"],
        "ë§¤íŠ¸ë¦¬ìŠ¤": ["ì¹¨ëŒ€", "ë² ë“œ", "ìˆ˜ë©´ìš©í’ˆ", "ì ìë¦¬"]
    },
    "related_terms": ["ì²´ì••ë¶„ì‚°", "ì§€ì§€ë ¥", "ë”±ë”±í•œ", "í•˜ë“œ", "ì²™ì¶”ì •ë ¬"],
    "search_queries": [
        "í—ˆë¦¬ ì•„í”ˆ ì‚¬ëŒ ë§¤íŠ¸ë¦¬ìŠ¤",
        "ìš”í†µ ì²™ì¶”í†µì¦ ë§¤íŠ¸ë¦¬ìŠ¤",
        "í—ˆë¦¬ë””ìŠ¤í¬ ì²´ì••ë¶„ì‚° ì§€ì§€ë ¥",
        "ë”±ë”±í•œ í•˜ë“œ ë§¤íŠ¸ë¦¬ìŠ¤ í—ˆë¦¬"
    ]
    }

    ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.
    """
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ì¿¼ë¦¬ ë¶„ì„: {user_query}"}
                ],
                max_tokens=500,
                temperature=0.3
            )
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                content = response.choices[0].message.content.strip()
                
                # JSON ì¶”ì¶œ ì‹œë„ (```json``` ë¸”ë¡ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬)
                if "```json" in content:
                    start = content.find("```json") + 7
                    end = content.find("```", start)
                    if end != -1:
                        content = content[start:end].strip()
                elif "```" in content:
                    start = content.find("```") + 3
                    end = content.find("```", start)
                    if end != -1:
                        content = content[start:end].strip()
                
                # ì¶”ê°€ ì •ë¦¬
                content = content.replace("```", "").strip()
                if content.startswith("json"):
                    content = content[4:].strip()
                
                result = json.loads(content)
                
                # ê²€ìƒ‰ì–´ ì¡°í•© ìƒì„±
                search_terms = [user_query]  # ì›ë³¸
                
                # GPT ë™ì˜ì–´ ê¸°ë°˜ ì¡°í•©
                if result.get('gpt_synonyms'):
                    for original, synonyms in result['gpt_synonyms'].items():
                        search_terms.extend(synonyms[:3])  # ìƒìœ„ 3ê°œ
                
                # ê´€ë ¨ ìš©ì–´ ì¶”ê°€
                if result.get('related_terms'):
                    search_terms.extend(result['related_terms'][:3])
                
                # ê²€ìƒ‰ ì¿¼ë¦¬ ì¶”ê°€
                if result.get('search_queries'):
                    search_terms.extend(result['search_queries'])
                
                # í™•ì¥ ì¿¼ë¦¬ ìƒì„±
                main_keywords = result.get('main_keywords', [])
                expanded_query = f"{user_query} {' '.join(main_keywords[:3])}" if main_keywords else user_query
                
                return {
                    'original_query': user_query,
                    'expanded_query': expanded_query,
                    'main_keywords': main_keywords,
                    'gpt_synonyms': result.get('gpt_synonyms', {}),
                    'related_terms': result.get('related_terms', []),
                    'search_terms': list(set(search_terms))[:8],  # ì¤‘ë³µ ì œê±°, ìµœëŒ€ 8ê°œ
                    'gpt_enhanced': True
                }
                
            except json.JSONDecodeError as e:
                logger.error(f"GPT ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                logger.error(f"ì‘ë‹µ ë‚´ìš©: {content}")
                # í´ë°±ìœ¼ë¡œ ë‹¨ìˆœ í™•ì¥
                return self._create_simple_expansion(user_query)
                
        except Exception as e:
            logger.error(f"GPT ì¿¼ë¦¬ í™•ì¥ ì‹¤íŒ¨: {e}")
        
        return self._fallback_query_expansion(user_query)


    def _create_simple_expansion(self, user_query: str) -> Dict[str, Any]:
        """JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ë‹¨ìˆœ í™•ì¥"""
        keywords = user_query.split()
        
        return {
            'original_query': user_query,
            'expanded_query': user_query,
            'main_keywords': keywords,
            'gpt_synonyms': {},
            'related_terms': [],
            'search_terms': [user_query],
            'gpt_enhanced': False
        }

    def analyze_user_intent_with_few_shot(self, user_query: str) -> Dict:
        """Few-shot ê°•í™” ì‚¬ìš©ì ì˜ë„ ë¶„ì„"""
        if not self.client:
            return self._basic_intent_analysis(user_query)
        
        try:
            system_prompt = """
ë§¤íŠ¸ë¦¬ìŠ¤ ì „ë¬¸ê°€ë¡œì„œ ì‚¬ìš©ì ì˜ë„ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

Few-shot ì˜ˆì‹œ:
ì…ë ¥: "í—ˆë¦¬ ë””ìŠ¤í¬ í™˜ì ë”±ë”±í•œ ë§¤íŠ¸ë¦¬ìŠ¤ 80ë§Œì› ì´í•˜"
ì¶œë ¥: {
  "intent_type": "health_focused",
  "urgency": "high",
  "budget_info": {
    "has_budget": true,
    "range": "80ë§Œì› ì´í•˜",
    "min": 0,
    "max": 80
  },
  "health_info": {
    "has_issue": true,
    "issues": ["í—ˆë¦¬", "ë””ìŠ¤í¬"],
    "severity": "high"
  },
  "preferences": {
    "firmness": "ë”±ë”±",
    "health_priority": true
  },
  "confidence": 0.95
}

ì…ë ¥: "ì‹ í˜¼ë¶€ë¶€ìš© í‚¹ì‚¬ì´ì¦ˆ ì¿¨ë§ ë§¤íŠ¸ë¦¬ìŠ¤"
ì¶œë ¥: {
  "intent_type": "lifestyle_focused",
  "urgency": "medium", 
  "budget_info": {"has_budget": false},
  "health_info": {"has_issue": false, "issues": []},
  "preferences": {
    "size": "í‚¹",
    "temperature": "ì‹œì›í•¨",
    "user_type": "ì»¤í”Œ"
  },
  "confidence": 0.90
}

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
"""
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ì˜ë„ ë¶„ì„: {user_query}"}
                ],
                max_tokens=400,
                temperature=0.2
            )
            
            try:
                intent = json.loads(response.choices[0].message.content.strip())
                intent['few_shot_enhanced'] = True
                logger.info(f"Few-shot ì˜ë„ ë¶„ì„: {intent.get('intent_type', 'unknown')}")
                return intent
            except json.JSONDecodeError:
                logger.error("Few-shot ì˜ë„ ë¶„ì„ JSON íŒŒì‹± ì‹¤íŒ¨")
                
        except Exception as e:
            logger.error(f"Few-shot ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return self._basic_intent_analysis(user_query)
    
    def _fallback_query_expansion(self, user_query: str) -> Dict[str, Any]:
        """í´ë°± ì¿¼ë¦¬ í™•ì¥"""
        return {
            'original_query': user_query,
            'expanded_query': user_query,
            'main_keywords': user_query.split(),
            'gpt_synonyms': {},
            'related_terms': [],
            'search_terms': [user_query],
            'gpt_enhanced': False
        }
    
    def _basic_intent_analysis(self, user_query: str) -> Dict:
        """ê¸°ë³¸ ì˜ë„ ë¶„ì„"""
        query_lower = user_query.lower()
        
        intent = {
            'intent_type': 'search',
            'urgency': 'medium',
            'budget_info': {'has_budget': False},
            'health_info': {'has_issue': False, 'issues': []},
            'preferences': {},
            'confidence': 0.5,
            'few_shot_enhanced': False
        }
        
        # ê±´ê°• ì´ìŠˆ ê°ì§€
        health_keywords = ['í—ˆë¦¬', 'ëª©', 'ì–´ê¹¨', 'ê´€ì ˆ', 'í†µì¦', 'ì•„í””', 'ë””ìŠ¤í¬']
        found_health = [kw for kw in health_keywords if kw in query_lower]
        if found_health:
            intent['health_info'] = {
                'has_issue': True,
                'issues': found_health,
                'severity': 'high' if any(word in query_lower for word in ['í†µì¦', 'ì•„í””']) else 'medium'
            }
            intent['urgency'] = 'high'
            intent['intent_type'] = 'health_focused'
        
        # ì˜ˆì‚° ê°ì§€
        budget_pattern = r'(\d+)\s*ë§Œì›'
        budget_matches = re.findall(budget_pattern, query_lower)
        if budget_matches:
            budgets = [int(b) for b in budget_matches]
            intent['budget_info'] = {
                'has_budget': True,
                'range': f"{min(budgets)}-{max(budgets)}ë§Œì›" if len(budgets) > 1 else f"{budgets[0]}ë§Œì›",
                'min': min(budgets),
                'max': max(budgets)
            }
        
        return intent


class EnhancedResponseGenerator:
    """Few-shot ê°•í™” ì‘ë‹µ ìƒì„±ê¸°"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-3.5-turbo"):
        self.client = None
        self.model = model
        
        if not OPENAI_AVAILABLE:
            logger.warning("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return
        
        api_key = api_key or os.getenv('OPENAI_API_KEY')
        if not api_key:
            logger.warning("OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return
        
        try:
            self.client = OpenAI(api_key=api_key)
            logger.info(f"Enhanced ì‘ë‹µ ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {self.model})")
        except Exception as e:
            logger.error(f"OpenAI ì‘ë‹µ ìƒì„±ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def generate_enhanced_response(self, user_query: str, search_results: List[Dict], 
                                 user_intent: Optional[Dict] = None,
                                 query_expansion: Optional[Dict] = None) -> str:
        """Few-shot ê°•í™” ì‘ë‹µ ìƒì„±"""
        if not self.client:
            return self._generate_fallback_response(user_query, search_results)
        
        if not search_results:
            return self._generate_no_results_response(user_query, user_intent)
        
        try:
            # Few-shot ì˜ˆì‹œ í¬í•¨ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_prompt = """
15ë…„ ê²½ë ¥ ë§¤íŠ¸ë¦¬ìŠ¤ ì „ë¬¸ê°€ë¡œì„œ ê³ ê°ì—ê²Œ ìµœì í™”ëœ ìƒë‹´ì„ ì œê³µí•˜ì„¸ìš”.

Few-shot ì‘ë‹µ ì˜ˆì‹œ:

ì˜ˆì‹œ 1:
ê³ ê° ì§ˆë¬¸: "í—ˆë¦¬ ë””ìŠ¤í¬ í™˜ììš© ë”±ë”±í•œ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œ"
ê²€ìƒ‰ ê²°ê³¼: ì—ì´ìŠ¤ BPA 1000 í•˜ë“œ (69ë§Œì›, ë³¸ë„¬ìŠ¤í”„ë§, ì²™ì¶”ì§€ì§€)
ì „ë¬¸ê°€ ì‘ë‹µ: "í—ˆë¦¬ ë””ìŠ¤í¬ë¡œ ê³ ìƒí•˜ê³  ê³„ì‹œëŠ”êµ°ìš”. 'ì—ì´ìŠ¤ BPA 1000 í•˜ë“œ'ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤. 69ë§Œì›ìœ¼ë¡œ ë³¸ë„¬ìŠ¤í”„ë§ êµ¬ì¡°ì˜ ë”±ë”±í•œ íƒ€ì…ì´ë©°, ì²™ì¶”ì§€ì§€ë ¥ì´ ë›°ì–´ë‚˜ ë””ìŠ¤í¬ í™˜ìë¶„ë“¤ê»˜ íš¨ê³¼ì ì…ë‹ˆë‹¤. í•˜ë“œ íƒ€ì…ì´ë¼ í—ˆë¦¬ê°€ ê³¼ë„í•˜ê²Œ êº¾ì´ì§€ ì•Šë„ë¡ ë„ì™€ì£¼ê³ , ì²´ì¤‘ ë¶„ì‚°ë„ ìš°ìˆ˜í•©ë‹ˆë‹¤."

ì˜ˆì‹œ 2:
ê³ ê° ì§ˆë¬¸: "ë”ìœ„ íƒ€ëŠ” ì‚¬ëŒìš© ì‹œì›í•œ ë§¤íŠ¸ë¦¬ìŠ¤"
ê²€ìƒ‰ ê²°ê³¼: í¼í”Œ ê·¸ë¦¬ë“œ (180ë§Œì›, ì ¤ê·¸ë¦¬ë“œ, ì¿¨ë§)
ì „ë¬¸ê°€ ì‘ë‹µ: "ë”ìœ„ë¥¼ ë§ì´ íƒ€ì‹œëŠ”êµ°ìš”. 'í¼í”Œ ê·¸ë¦¬ë“œ'ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤. 180ë§Œì›ìœ¼ë¡œ í”„ë¦¬ë¯¸ì—„ì´ì§€ë§Œ ì ¤ê·¸ë¦¬ë“œ ê¸°ìˆ ë¡œ íƒì›”í•œ ì¿¨ë§ íš¨ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë…íŠ¹í•œ ê·¸ë¦¬ë“œ êµ¬ì¡°ê°€ ê³µê¸° ìˆœí™˜ì„ ê·¹ëŒ€í™”í•˜ì—¬ ì—¬ë¦„ì² ì—ë„ ì‹œì›í•˜ê²Œ ì£¼ë¬´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."

ì‘ë‹µ ê°€ì´ë“œë¼ì¸:
1. ê³ ê° ìƒí™© ê³µê° í‘œí˜„
2. ì¶”ì²œ ë§¤íŠ¸ë¦¬ìŠ¤ëª…ê³¼ ê°€ê²© ëª…ì‹œ
3. í•µì‹¬ íŠ¹ì§• 2-3ê°œ ì„¤ëª…
4. ê³ ê° ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” êµ¬ì²´ì  ì´ìœ 
5. ì „ë¬¸ì ì´ë©´ì„œ ì¹œê·¼í•œ í†¤, ì¬ì¹˜ìˆìœ¼ë©´ì„œ ì¹­ì°¬í•˜ëŠ” í†¤
6. 300-400ì ë‚´ì™¸
"""
            
            # ê²€ìƒ‰ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸ (ìƒìœ„ 1ê°œë§Œ ì‚¬ìš©)
            top_mattress = search_results[0]
            context = f"""
ì¶”ì²œ ë§¤íŠ¸ë¦¬ìŠ¤:
- ì´ë¦„: {top_mattress.get('name', 'Unknown')}
- ë¸Œëœë“œ: {top_mattress.get('brand', 'Unknown')}  
- ê°€ê²©: {top_mattress.get('price', 0)}ë§Œì›
- íƒ€ì…: {top_mattress.get('type', 'Unknown')}
- íŠ¹ì§•: {', '.join(top_mattress.get('features', [])[:3])}
- ì¶”ì²œëŒ€ìƒ: {', '.join(top_mattress.get('target_users', [])[:2])}
- ìœ ì‚¬ë„: {top_mattress.get('similarity_score', 0):.3f}
"""
            
            # ì‚¬ìš©ì ì˜ë„ ì •ë³´
            intent_info = ""
            if user_intent:
                intent_parts = []
                
                if user_intent.get('health_info', {}).get('has_issue'):
                    issues = user_intent['health_info'].get('issues', [])
                    intent_parts.append(f"ê±´ê°• ì´ìŠˆ: {', '.join(issues)}")
                
                if user_intent.get('budget_info', {}).get('has_budget'):
                    intent_parts.append(f"ì˜ˆì‚°: {user_intent['budget_info'].get('range', '')}")
                
                preferences = user_intent.get('preferences', {})
                if preferences:
                    pref_list = [f"{k}: {v}" for k, v in preferences.items() if v]
                    if pref_list:
                        intent_parts.append(f"ì„ í˜¸ë„: {', '.join(pref_list)}")
                
                if intent_parts:
                    intent_info = f"\n\nê³ ê° ìš”êµ¬ì‚¬í•­: {' | '.join(intent_parts)}"
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ê³ ê° ì§ˆë¬¸: {user_query}\n\n{context}{intent_info}"}
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            final_response = response.choices[0].message.content.strip()
            logger.info("Enhanced ì‘ë‹µ ìƒì„± ì™„ë£Œ")
            return final_response
            
        except Exception as e:
            logger.error(f"Enhanced ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._generate_fallback_response(user_query, search_results)
    
    def _generate_no_results_response(self, user_query: str, user_intent: Optional[Dict]) -> str:
        """ê²°ê³¼ ì—†ìŒ ì‘ë‹µ"""
        return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì¡°ê±´ì— ë§ëŠ” ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¡°ê±´ì„ ì¡°ì •í•´ì„œ ë‹¤ì‹œ ê²€ìƒ‰í•´ë³´ì‹œê² ì–´ìš”?"
    
    def _generate_fallback_response(self, user_query: str, search_results: List[Dict]) -> str:
        """í´ë°± ì‘ë‹µ"""
        if not search_results:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì¡°ê±´ì— ë§ëŠ” ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        top_mattress = search_results[0]
        features = top_mattress.get('features', [])[:2]
        features_text = ', '.join(features) if features else 'ìš°ìˆ˜í•œ í’ˆì§ˆ'
        
        return f"{top_mattress.get('name', 'Unknown')}ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤. {top_mattress.get('price', 0)}ë§Œì›ìœ¼ë¡œ {features_text}ê°€ íŠ¹ì§•ì´ë©°, ê³ ê°ë‹˜ì˜ ìš”êµ¬ì‚¬í•­ì— ì í•©í•©ë‹ˆë‹¤."


class ConversationManager:
    """ëŒ€í™” ê´€ë¦¬"""
    
    def __init__(self):
        self.conversation_history = []
        self.user_context = {}
        self.session_start = datetime.now()
        self.interaction_count = 0
    
    def add_interaction(self, user_query: str, agent_response: str, 
                       search_results: Optional[List[Dict]] = None,
                       user_intent: Optional[Dict] = None,
                       query_expansion: Optional[Dict] = None,
                       filtered_question: bool = False):
        """ëŒ€í™” ê¸°ë¡ ì¶”ê°€"""
        self.interaction_count += 1
        
        interaction = {
            'id': self.interaction_count,
            'timestamp': datetime.now().isoformat(),
            'user_query': user_query,
            'agent_response': agent_response,
            'search_results_count': len(search_results) if search_results else 0,
            'user_intent': user_intent,
            'query_expansion': query_expansion,
            'top_result': search_results[0] if search_results else None,
            'filtered_question': filtered_question,
            'enhanced_features': {
                'gpt_synonyms_used': query_expansion.get('gpt_enhanced', False) if query_expansion else False,
                'few_shot_enhanced': user_intent.get('few_shot_enhanced', False) if user_intent else False
            }
        }
        
        self.conversation_history.append(interaction)
        
        if user_intent:
            self._update_user_context(user_intent)
    
    def _update_user_context(self, user_intent: Dict):
        """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        # ì˜ˆì‚° ì •ë³´
        budget_info = user_intent.get('budget_info', {})
        if budget_info.get('has_budget'):
            self.user_context['current_budget'] = budget_info
        
        # ê±´ê°• ì´ìŠˆ
        health_info = user_intent.get('health_info', {})
        if health_info.get('has_issue'):
            if 'health_issues' not in self.user_context:
                self.user_context['health_issues'] = set()
            self.user_context['health_issues'].update(health_info.get('issues', []))
        
        # ì„ í˜¸ë„
        preferences = user_intent.get('preferences', {})
        if preferences:
            if 'preferences' not in self.user_context:
                self.user_context['preferences'] = {}
            self.user_context['preferences'].update(preferences)
    
    def get_conversation_summary(self) -> Dict:
        """ëŒ€í™” ìš”ì•½"""
        enhanced_count = len([h for h in self.conversation_history 
                            if h.get('enhanced_features', {}).get('gpt_synonyms_used')])
        
        return {
            'total_interactions': self.interaction_count,
            'enhanced_interactions': enhanced_count,
            'enhancement_rate': enhanced_count / max(self.interaction_count, 1),
            'user_context': self.user_context,
            'session_start': self.session_start.isoformat()
        }


class EnhancedMattressAIAgent:
    """Enhanced ë§¤íŠ¸ë¦¬ìŠ¤ AI ì—ì´ì „íŠ¸"""
    
    def __init__(self, api_key: Optional[str] = None, data_path: Optional[str] = None, 
                 model: str = "gpt-3.5-turbo"):
        
        # Enhanced RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        try:
            self.rag_system, rag_success = setup_enhanced_rag_system(
                data_path=data_path, 
                openai_api_key=api_key
            )
            if not rag_success:
                raise RuntimeError("Enhanced RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
        except Exception as e:
            logger.error(f"Enhanced RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            raise
        
        # Enhanced OpenAI ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.query_processor = EnhancedQueryProcessor(api_key, model)
        self.response_generator = EnhancedResponseGenerator(api_key, model)
        
        # ëŒ€í™” ê´€ë¦¬ì
        self.conversation_manager = ConversationManager()
        
         # ê´€ë ¨ì„± ì²´í¬ ì¶”ê°€ <<<<
        gpt_client = self.query_processor.client if self.query_processor else None
        self.relevance_checker = SmartRelevanceChecker(gpt_client)
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.is_ready = True
        self.openai_available = (self.query_processor.client is not None and 
                               self.response_generator.client is not None)
        
        logger.info("Enhanced ë§¤íŠ¸ë¦¬ìŠ¤ AI ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"Enhanced RAG: {'âœ…' if rag_success else 'âŒ'}")
        logger.info(f"OpenAI í†µí•©: {'âœ…' if self.openai_available else 'âŒ'}")
        logger.info(f"GPT ë™ì˜ì–´: {'âœ…' if self.rag_system.gpt_available else 'âŒ'}")
        logger.info(f"ëª¨ë¸: {model}")
    
    def process_query(self, user_query: str, n_results: int = 5) -> Dict:
        """Enhanced ì¿¼ë¦¬ ì²˜ë¦¬ (GPT ë™ì˜ì–´ + Few-shot + ë‹¤ì¤‘ ì „ëµ)"""
        if not self.is_ready:
            return {
                'error': 'Enhanced AI ì—ì´ì „íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤',
                'user_query': user_query,
                'timestamp': datetime.now().isoformat(),
                'success': False
            }
        
        logger.info(f"Enhanced AI ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì‹œì‘: '{user_query}'")
        start_time = time.time()
        
        try:
            # Step 0: ê´€ë ¨ì„± ì²´í¬ (ìƒˆë¡œ ì¶”ê°€) <<<<
            logger.info("Step 0: ì§ˆë¬¸ ê´€ë ¨ì„± ì²´í¬")
            relevance_result = self.relevance_checker.check_relevance(user_query)
            
            if not relevance_result['is_relevant']:
                # ë¬´ê´€í•œ ì§ˆë¬¸ì— ëŒ€í•œ ì•ˆë‚´ ì‘ë‹µ
                irrelevant_response = self.relevance_checker.get_irrelevant_response(
                    user_query, relevance_result['reason']
                )
                
                # ëŒ€í™” ê¸°ë¡ ì €ì¥ (í•„í„°ë§ëœ ì§ˆë¬¸ìœ¼ë¡œ)
                self.conversation_manager.add_interaction(
                    user_query, irrelevant_response, [], None, None, filtered_question=True
                )
                
                return {
                    'user_query': user_query,
                    'agent_response': irrelevant_response,
                    'relevance_check': relevance_result,
                    'search_results': [],
                    'total_results': 0,
                    'processing_time': round(time.time() - start_time, 2),
                    'enhancement_info': {
                        'question_filtered': True,
                        'filter_reason': relevance_result['reason'],
                        'filter_method': relevance_result.get('method', 'unknown')
                    },
                    'openai_used': self.openai_available,
                    'timestamp': datetime.now().isoformat(),
                    'success': True,
                    'filtered_question': True
                }


            # Step 1: GPT ê¸°ë°˜ ì‚¬ìš©ì ì˜ë„ ë¶„ì„ (Few-shot ê°•í™”)
            logger.info("Step 1: Enhanced ì‚¬ìš©ì ì˜ë„ ë¶„ì„")
            user_intent = self.query_processor.analyze_user_intent_with_few_shot(user_query)
            
            # Step 2: GPT ë™ì˜ì–´ ê¸°ë°˜ ì¿¼ë¦¬ í™•ì¥
            logger.info("Step 2: GPT ë™ì˜ì–´ ì¿¼ë¦¬ í™•ì¥")
            query_expansion = self.query_processor.expand_query_with_gpt_synonyms(user_query)
            
            # Step 3: Enhanced RAG ê²€ìƒ‰ (ë‹¤ì¤‘ ì „ëµ)
            logger.info("Step 3: Enhanced RAG ë‹¤ì¤‘ ì „ëµ ê²€ìƒ‰")
            
            # ì˜ˆì‚° í•„í„° ì¤€ë¹„
            budget_filter = None
            budget_info = user_intent.get('budget_info', {})
            if budget_info.get('has_budget'):
                budget_min = budget_info.get('min', 0)
                budget_max = budget_info.get('max', 1000)
                budget_filter = (budget_min, budget_max)
            
            # Enhanced RAG ê²€ìƒ‰ ì‹¤í–‰
            search_results = self.rag_system.search_mattresses(
                user_query, 
                n_results=n_results,
                budget_filter=budget_filter
            )
            
            # Step 4: Enhanced ì‘ë‹µ ìƒì„± (Few-shot ê°•í™”)
            logger.info("Step 4: Enhanced ì‘ë‹µ ìƒì„±")
            agent_response = self.response_generator.generate_enhanced_response(
                user_query, search_results, user_intent, query_expansion
            )
            
            # ëŒ€í™” ê¸°ë¡ ì €ì¥
            self.conversation_manager.add_interaction(
                user_query, agent_response, search_results, user_intent, query_expansion
            )
            
            end_time = time.time()
            
            # í–¥ìƒëœ ê²°ê³¼ êµ¬ì„±
            result = {
                'user_query': user_query,
                'user_intent': user_intent,
                'query_expansion': query_expansion,
                'search_results': search_results,
                'agent_response': agent_response,
                'total_results': len(search_results),
                'processing_time': round(end_time - start_time, 2),
                'enhancement_info': {
                    'gpt_synonyms_used': query_expansion.get('gpt_enhanced', False),
                    'few_shot_enhanced': user_intent.get('few_shot_enhanced', False),
                    'enhanced_rag_used': True,
                    'strategies_used': search_results[0].get('strategies_used', []) if search_results else []
                },
                'similarity_scores': [r.get('similarity_score', 0) for r in search_results],
                'avg_similarity': sum(r.get('similarity_score', 0) for r in search_results) / len(search_results) if search_results else 0,
                'openai_used': self.openai_available,
                'timestamp': datetime.now().isoformat(),
                'success': True
            }
            
            logger.info(f"Enhanced AI ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì™„ë£Œ ({result['processing_time']}ì´ˆ)")
            logger.info(f"í‰ê·  ìœ ì‚¬ë„: {result['avg_similarity']:.3f}")
            return result
            
        except Exception as e:
            logger.error(f"Enhanced AI ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'error': str(e),
                'user_query': user_query,
                'success': False,
                'timestamp': datetime.now().isoformat()
            }
    
    def get_personalized_recommendations(self, n_results: int = 5) -> List[Dict]:
        """ê°œì¸í™” ì¶”ì²œ (Enhanced)"""
        try:
            user_profile = self.conversation_manager.get_conversation_summary()['user_context']
            
            # ê°œì¸í™” ì¿¼ë¦¬ ìƒì„±
            query_parts = []
            
            if user_profile.get('health_issues'):
                query_parts.extend(list(user_profile['health_issues']))
            
            preferences = user_profile.get('preferences', {})
            if preferences:
                for key, value in preferences.items():
                    if value:
                        query_parts.append(f"{key} {value}")
            
            personalized_query = ' '.join(query_parts) if query_parts else "ì¶”ì²œ ë§¤íŠ¸ë¦¬ìŠ¤"
            
            # ì˜ˆì‚° í•„í„°
            budget_filter = None
            current_budget = user_profile.get('current_budget', {})
            if current_budget.get('has_budget'):
                budget_filter = (current_budget.get('min', 0), current_budget.get('max', 1000))
            
            # Enhanced ê²€ìƒ‰
            results = self.rag_system.search_mattresses(
                personalized_query, 
                n_results=n_results,
                budget_filter=budget_filter
            )
            
            # ê°œì¸í™” ì ìˆ˜ ì¶”ê°€
            for result in results:
                result['personalized'] = True
                # ê°œì¸í™” ë³´ë„ˆìŠ¤ ì ìš©
                original_score = result.get('similarity_score', 0)
                personalization_bonus = 0.1 if user_profile.get('health_issues') else 0.05
                result['similarity_score'] = min(original_score + personalization_bonus, 1.0)
            
            return results
            
        except Exception as e:
            logger.error(f"ê°œì¸í™” ì¶”ì²œ ì‹¤íŒ¨: {e}")
            return []
    
    def compare_mattresses(self, mattress_ids: List[str]) -> Dict:
        """ë§¤íŠ¸ë¦¬ìŠ¤ ë¹„êµ ë¶„ì„ (Enhanced)"""
        try:
            mattresses = []
            for mattress_id in mattress_ids:
                mattress = self.rag_system.get_mattress_by_id(mattress_id)
                if mattress:
                    mattresses.append(mattress)
            
            if not mattresses:
                return {'error': 'ë¹„êµí•  ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}
            
            comparison = {
                'mattresses': mattresses,
                'comparison_table': {},
                'enhanced_analysis': None
            }
            
            # ê¸°ë³¸ ë¹„êµ í…Œì´ë¸”
            attributes = ['price', 'type', 'brand', 'features']
            for attr in attributes:
                comparison['comparison_table'][attr] = []
                for mattress in mattresses:
                    if attr == 'features':
                        features = mattress.get(attr, [])
                        comparison['comparison_table'][attr].append(features[:3] if features else [])
                    else:
                        comparison['comparison_table'][attr].append(mattress.get(attr, 'ì •ë³´ ì—†ìŒ'))
            
            # Enhanced AI ë¹„êµ ë¶„ì„
            if self.response_generator.client:
                try:
                    mattress_info = []
                    for m in mattresses:
                        features = m.get('features', [])
                        features_text = ', '.join(features[:3]) if features else 'ì •ë³´ ì—†ìŒ'
                        mattress_info.append(
                            f"- {m.get('name', 'Unknown')} ({m.get('brand', 'Unknown')}): "
                            f"{m.get('price', 0)}ë§Œì›, {m.get('type', 'Unknown')}, {features_text}"
                        )
                    
                    system_prompt = f"""
ë§¤íŠ¸ë¦¬ìŠ¤ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ë§¤íŠ¸ë¦¬ìŠ¤ë“¤ì„ ì‹¬ì¸µ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”:

{chr(10).join(mattress_info)}

ë¶„ì„ ê´€ì :
1. ê°€ê²© ëŒ€ë¹„ ì„±ëŠ¥ ë¶„ì„
2. ê±´ê°•ìƒ ì¥ì  ë¹„êµ 
3. ë‚´êµ¬ì„± ë° í’ˆì§ˆ í‰ê°€
4. ê° ë§¤íŠ¸ë¦¬ìŠ¤ ìµœì  ì‚¬ìš©ì
5. í•µì‹¬ ì¥ë‹¨ì  ìš”ì•½

ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ 400-500ìë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
                    
                    response = self.response_generator.client.chat.completions.create(
                        model=self.response_generator.model,
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": "ìœ„ ë§¤íŠ¸ë¦¬ìŠ¤ë“¤ì„ ì „ë¬¸ì ìœ¼ë¡œ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”."}
                        ],
                        max_tokens=600,
                        temperature=0.6
                    )
                    
                    comparison['enhanced_analysis'] = response.choices[0].message.content.strip()
                    
                except Exception as e:
                    logger.error(f"Enhanced ë¹„êµ ë¶„ì„ ì‹¤íŒ¨: {e}")
                    comparison['enhanced_analysis'] = "Enhanced ë¶„ì„ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            return comparison
            
        except Exception as e:
            logger.error(f"ë§¤íŠ¸ë¦¬ìŠ¤ ë¹„êµ ì‹¤íŒ¨: {e}")
            return {'error': f'ë¹„êµ ë¶„ì„ ì‹¤íŒ¨: {str(e)}'}
    
    def get_agent_status(self) -> Dict:
        """Enhanced ì—ì´ì „íŠ¸ ìƒíƒœ"""
        try:
            rag_status = self.rag_system.get_system_status()
            conversation_summary = self.conversation_manager.get_conversation_summary()
            
            return {
                'ready': self.is_ready,
                'enhanced_rag_system': rag_status,
                'openai_available': self.openai_available,
                'openai_model': getattr(self.query_processor, 'model', 'N/A'),
                'conversation': conversation_summary,
                'enhanced_capabilities': {
                    'gpt_dynamic_synonyms': rag_status.get('gpt_available', False),
                    'few_shot_learning': True,
                    'multi_strategy_search': True,
                    'enhanced_query_expansion': self.openai_available,
                    'enhanced_intent_analysis': self.openai_available,
                    'enhanced_response_generation': self.openai_available,
                    'personalization': True,
                    'comparison_analysis': self.openai_available
                },
                'enhancement_stats': {
                    'total_interactions': conversation_summary['total_interactions'],
                    'enhanced_interactions': conversation_summary['enhanced_interactions'],
                    'enhancement_rate': conversation_summary['enhancement_rate']
                },
                'session_start': self.conversation_manager.session_start.isoformat()
            }
        except Exception as e:
            logger.error(f"ìƒíƒœ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'ready': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }


# í¸ì˜ í•¨ìˆ˜
def create_enhanced_mattress_agent(api_key: Optional[str] = None, data_path: Optional[str] = None,
                                 model: str = "gpt-3.5-turbo") -> EnhancedMattressAIAgent:
    """Enhanced ë§¤íŠ¸ë¦¬ìŠ¤ AI ì—ì´ì „íŠ¸ ìƒì„±"""
    try:
        agent = EnhancedMattressAIAgent(api_key, data_path, model)
        logger.info("âœ… Enhanced ë§¤íŠ¸ë¦¬ìŠ¤ AI ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ")
        return agent
    except Exception as e:
        logger.error(f"Enhanced AI ì—ì´ì „íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        raise


# ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
MattressAIAgent = EnhancedMattressAIAgent
create_mattress_agent = create_enhanced_mattress_agent


# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸš€ Enhanced ë§¤íŠ¸ë¦¬ìŠ¤ AI ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    
    try:
        # Enhanced AI ì—ì´ì „íŠ¸ ìƒì„±
        api_key = os.getenv('OPENAI_API_KEY')
        agent = create_enhanced_mattress_agent(api_key)
        
        # ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸
        status = agent.get_agent_status()
        print(f"\nğŸ“Š Enhanced ì—ì´ì „íŠ¸ ìƒíƒœ:")
        print(f"  ì¤€ë¹„ ìƒíƒœ: {status['ready']}")
        print(f"  Enhanced RAG: {status['enhanced_rag_system']['initialized']}")
        print(f"  OpenAI ì—°ë™: {status['openai_available']}")
        print(f"  GPT ë™ì˜ì–´: {status['enhanced_rag_system']['gpt_available']}")
        print(f"  ì‚¬ìš© ëª¨ë¸: {status.get('openai_model', 'N/A')}")
        
        enhanced_capabilities = status['enhanced_capabilities']
        print(f"\nğŸš€ Enhanced ê¸°ëŠ¥:")
        for feature, available in enhanced_capabilities.items():
            print(f"   {'âœ…' if available else 'âŒ'} {feature}")
        
        # Enhanced í…ŒìŠ¤íŠ¸
        test_queries = [
            "í—ˆë¦¬ ë””ìŠ¤í¬ í™˜ìì¸ë° ë”±ë”±í•˜ê³  ì¢‹ì€ ë§¤íŠ¸ë¦¬ìŠ¤ 80ë§Œì› ì´í•˜ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”",
            "ë”ìœ„ ë§ì´ íƒ€ëŠ” ì‚¬ëŒì´ ì“¸ ìˆ˜ ìˆëŠ” ì¿¨ë§ ë§¤íŠ¸ë¦¬ìŠ¤ ìˆë‚˜ìš”?",
            "ì‹ í˜¼ë¶€ë¶€ìš© í‚¹ì‚¬ì´ì¦ˆ ë©”ëª¨ë¦¬í¼ ë§¤íŠ¸ë¦¬ìŠ¤ ì°¾ê³  ìˆì–´ìš”",
            "50ë§Œì›ëŒ€ ê°€ì„±ë¹„ ì¢‹ì€ ë¸Œëœë“œ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œ"
        ]
        
        print(f"\nğŸ§ª Enhanced AI ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸:")
        
        for i, query in enumerate(test_queries, 1):
            print(f"\n{'='*70}")
            print(f"í…ŒìŠ¤íŠ¸ {i}: '{query}'")
            print(f"{'='*70}")
            
            result = agent.process_query(query, n_results=3)
            
            if result.get('success'):
                enhancement_info = result['enhancement_info']
                print(f"ğŸ¯ ì˜ë„ ë¶„ì„: {result['user_intent'].get('intent_type', 'unknown')}")
                print(f"ğŸ”§ GPT ë™ì˜ì–´: {enhancement_info['gpt_synonyms_used']}")
                print(f"ğŸ“ Few-shot ê°•í™”: {enhancement_info['few_shot_enhanced']}")
                print(f"ğŸ” ì‚¬ìš© ì „ëµ: {', '.join(enhancement_info['strategies_used'])}")
                print(f"ğŸ“Š í‰ê·  ìœ ì‚¬ë„: {result['avg_similarity']:.3f}")
                print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {result['processing_time']}ì´ˆ")
                
                if result['search_results']:
                    top_result = result['search_results'][0]
                    print(f"ğŸ¥‡ 1ìˆœìœ„: {top_result.get('name', 'Unknown')} ({top_result.get('brand', 'Unknown')})")
                    print(f"    ê°€ê²©: {top_result.get('price', 0)}ë§Œì›")
                    print(f"    ìœ ì‚¬ë„: {top_result.get('similarity_score', 0):.3f}")
                    print(f"    Enhanced: {top_result.get('gpt_enhanced', False)}")
                
                print(f"\nğŸ¤– Enhanced AI ì‘ë‹µ:")
                print(f"{'â”€' * 50}")
                print(f"{result['agent_response']}")
                print(f"{'â”€' * 50}")
                
            else:
                print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            
            if i < len(test_queries):
                time.sleep(2)  # API ì œí•œ ë°©ì§€
        
        # Enhancement í†µê³„
        final_status = agent.get_agent_status()
        enhancement_stats = final_status['enhancement_stats']
        print(f"\nğŸ“ˆ Enhancement í†µê³„:")
        print(f"  ì´ ìƒí˜¸ì‘ìš©: {enhancement_stats['total_interactions']}íšŒ")
        print(f"  Enhanced ìƒí˜¸ì‘ìš©: {enhancement_stats['enhanced_interactions']}íšŒ") 
        print(f"  Enhancement ì ìš©ë¥ : {enhancement_stats['enhancement_rate']:.1%}")
        
        print(f"\nâœ… Enhanced AI ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
