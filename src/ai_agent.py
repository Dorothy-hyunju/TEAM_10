"""
AI ì—ì´ì „íŠ¸ - OpenAI í…ìŠ¤íŠ¸ ìƒì„± ë° ReAct íŒ¨í„´
íŒŒì¼: src/ai_agent.py

ì—­í• :
- ì‚¬ìš©ì ì¿¼ë¦¬ ë¶„ì„ ë° ê°œì„ 
- RAG ê²°ê³¼ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
- ReAct íŒ¨í„´ êµ¬í˜„ (ì¶”ë¡ -í–‰ë™-ê´€ì°°)
- ëŒ€í™” ê´€ë¦¬ ë° ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
import openai
from openai import OpenAI
from datetime import datetime
import time
import re

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
import sys
sys.path.append(str(Path(__file__).parent.parent))
from src.rag_system import MattressRAGSystem, setup_rag_system

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OpenAITextManager:
    """OpenAI í…ìŠ¤íŠ¸ ìƒì„± ì „ìš© ë§¤ë‹ˆì €"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        OpenAI í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        Args:
            api_key: OpenAI API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´)
        """
        # API í‚¤ ì„¤ì •
        if api_key:
            self.api_key = api_key
        else:
            self.api_key = os.getenv('OPENAI_API_KEY')
            if not self.api_key:
                logger.warning(
                    "OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. "
                    "í…ìŠ¤íŠ¸ ê°œì„  ë° ì‘ë‹µ ìƒì„± ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                )
                self.client = None
                return
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            self.client = OpenAI(api_key=self.api_key)
            # ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸
            test_response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": "í…ŒìŠ¤íŠ¸"}],
                max_tokens=5
            )
            logger.info("OpenAI í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.client = None
    
    def enhance_query(self, user_query: str) -> str:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ OpenAIë¡œ ê°œì„ 
        
        Args:
            user_query: ì›ë³¸ ì‚¬ìš©ì ì¿¼ë¦¬
            
        Returns:
            str: ê°œì„ ëœ ì¿¼ë¦¬
        """
        if not self.client:
            logger.warning("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ì–´ ì¿¼ë¦¬ ê°œì„ ì„ ê±´ë„ˆëœë‹ˆë‹¤")
            return user_query
        
        try:
            system_prompt = """
ë‹¹ì‹ ì€ ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰ì— ìµœì í™”ëœ í‚¤ì›Œë“œì™€ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ë‹¤ìŒ ìš”ì†Œë“¤ì„ ì¶”ì¶œí•˜ê³  ê°•í™”í•˜ì„¸ìš”:
- ê±´ê°• ë¬¸ì œ (í—ˆë¦¬í†µì¦, ëª©í†µì¦, ê´€ì ˆì—¼ ë“±)
- ìˆ˜ë©´ ìì„¸ (ì˜†ìœ¼ë¡œ, ë“±ìœ¼ë¡œ, ì—ë“œë ¤ ë“±)
- ì„ í˜¸ë„ (ë”±ë”±í•¨, ë¶€ë“œëŸ¬ì›€, ì‹œì›í•¨ ë“±)  
- ì˜ˆì‚° ë²”ìœ„
- íŠ¹ë³„ ìš”êµ¬ì‚¬í•­ (ì»¤í”Œìš©, ì–´ë¦°ì´ìš© ë“±)
- ë¸Œëœë“œ ì„ í˜¸ë„

ì›ë³¸ ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ìœ ì§€í•˜ë©´ì„œ ê²€ìƒ‰ì— ìœ ë¦¬í•œ í˜•íƒœë¡œ ë³€í™˜í•˜ë˜, í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ í‚¤ì›Œë“œ ì¤‘ì‹¬ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ë‹¤ìŒ ì§ˆë¬¸ì„ ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰ìš©ìœ¼ë¡œ ê°œì„ í•´ì£¼ì„¸ìš”: {user_query}"}
                ],
                max_tokens=150,
                temperature=0.3
            )
            
            enhanced_query = response.choices[0].message.content.strip()
            logger.info(f"ì¿¼ë¦¬ ê°œì„ : '{user_query}' â†’ '{enhanced_query}'")
            return enhanced_query
            
        except Exception as e:
            logger.error(f"ì¿¼ë¦¬ ê°œì„  ì‹¤íŒ¨: {e}")
            return user_query  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜
    
    def analyze_user_intent(self, user_query: str) -> Dict:
        """
        ì‚¬ìš©ì ì˜ë„ ë¶„ì„
        
        Args:
            user_query: ì‚¬ìš©ì ì§ˆë¬¸
            
        Returns:
            Dict: ë¶„ì„ëœ ì‚¬ìš©ì ì˜ë„
        """
        if not self.client:
            # ê¸°ë³¸ ì˜ë„ ë¶„ì„ (ê·œì¹™ ê¸°ë°˜)
            intent = {
                'intent_type': 'search',
                'budget_range': None,
                'health_issues': [],
                'preferences': [],
                'confidence': 0.5
            }
            
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
            query_lower = user_query.lower()
            if any(word in query_lower for word in ['í—ˆë¦¬', 'ëª©', 'ê´€ì ˆ']):
                intent['health_issues'].append('í†µì¦')
            if any(word in query_lower for word in ['ì˜ˆì‚°', 'ë§Œì›', 'ì›']):
                intent['intent_type'] = 'budget_search'
            
            return intent
        
        try:
            system_prompt = """
ì‚¬ìš©ìì˜ ë§¤íŠ¸ë¦¬ìŠ¤ ê´€ë ¨ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ JSON í˜•íƒœë¡œ ì˜ë„ë¥¼ íŒŒì•…í•´ì£¼ì„¸ìš”:

{
  "intent_type": "search|compare|recommend|info|budget_search",
  "budget_range": "ì˜ˆì‚° ë²”ìœ„ (ì˜ˆ: 50-100ë§Œì›)",
  "health_issues": ["í—ˆë¦¬í†µì¦", "ëª©í†µì¦", "ê´€ì ˆì—¼" ë“±],
  "sleep_position": "ì˜†ìœ¼ë¡œ|ë“±ìœ¼ë¡œ|ì—ë“œë ¤|í˜¼í•©",
  "preferences": ["ë”±ë”±í•¨", "ë¶€ë“œëŸ¬ì›€", "ì‹œì›í•¨", "ë”°ëœ»í•¨" ë“±],
  "size_preference": "ì‹±ê¸€|í€¸|í‚¹|ìŠˆí¼í‚¹",
  "special_requirements": ["ì»¤í”Œìš©", "ì–´ë¦°ì´ìš©", "ë…¸ì¸ìš©" ë“±],
  "urgency": "high|medium|low",
  "confidence": 0.0-1.0
}

ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”: {user_query}"}
                ],
                max_tokens=300,
                temperature=0.2
            )
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                intent = json.loads(response.choices[0].message.content.strip())
                logger.info(f"ì‚¬ìš©ì ì˜ë„ ë¶„ì„ ì™„ë£Œ: {intent.get('intent_type', 'unknown')}")
                return intent
            except json.JSONDecodeError:
                logger.error("ì˜ë„ ë¶„ì„ ê²°ê³¼ JSON íŒŒì‹± ì‹¤íŒ¨")
                return {'intent_type': 'search', 'confidence': 0.3}
                
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {'intent_type': 'search', 'confidence': 0.1}
    
    def generate_response(self, user_query: str, search_results: List[Dict], 
                         user_intent: Optional[Dict] = None) -> str:
        """
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒí™©ì— ë§ëŠ” ì‘ë‹µ ìƒì„±
        
        Args:
            user_query: ì‚¬ìš©ì ì›ë³¸ ì§ˆë¬¸
            search_results: RAG ê²€ìƒ‰ ê²°ê³¼
            user_intent: ë¶„ì„ëœ ì‚¬ìš©ì ì˜ë„
            
        Returns:
            str: ìƒí™©ì— ë§ëŠ” ì‘ë‹µ
        """
        if not self.client:
            # OpenAI ì—†ì´ ê¸°ë³¸ ì‘ë‹µ ìƒì„±
            return self._generate_fallback_response(user_query, search_results)
        
        if not search_results:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì¡°ê±´ì— ë§ëŠ” ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ê²€ìƒ‰í•´ë³´ì‹œê² ì–´ìš”?"
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ìƒìœ„ 3ê°œ ê²°ê³¼ë§Œ ì‚¬ìš©)
            context_parts = []
            for mattress in search_results[:3]:
                features_text = ', '.join(mattress['features'][:3]) if mattress['features'] else 'ì •ë³´ ì—†ìŒ'
                target_users_text = ', '.join(mattress['target_users'][:2]) if mattress['target_users'] else ''
                
                context_parts.append(
                    f"- {mattress['name']} ({mattress['brand']}): "
                    f"{mattress['type']} íƒ€ì…, {mattress['price']}ë§Œì›, "
                    f"íŠ¹ì§•: {features_text}"
                    f"{', ì¶”ì²œ: ' + target_users_text if target_users_text else ''}"
                )
            
            context = "\n".join(context_parts)
            
            # ì‚¬ìš©ì ì˜ë„ ì •ë³´ ì¶”ê°€
            intent_info = ""
            if user_intent:
                intent_parts = []
                if user_intent.get('health_issues'):
                    intent_parts.append(f"ê±´ê°• ì´ìŠˆ: {', '.join(user_intent['health_issues'])}")
                if user_intent.get('budget_range'):
                    intent_parts.append(f"ì˜ˆì‚°: {user_intent['budget_range']}")
                if user_intent.get('preferences'):
                    intent_parts.append(f"ì„ í˜¸ë„: {', '.join(user_intent['preferences'])}")
                
                if intent_parts:
                    intent_info = f"\n\nê³ ê° ì •ë³´: {' | '.join(intent_parts)}"
            
            system_prompt = f"""
ë‹¹ì‹ ì€ 10ë…„ ê²½ë ¥ì˜ ë§¤íŠ¸ë¦¬ìŠ¤ ì „ë¬¸ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ê³ ê°ì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê²€ìƒ‰ëœ ë§¤íŠ¸ë¦¬ìŠ¤ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ì¹œê·¼í•œ ìƒë‹´ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ê²€ìƒ‰ëœ ë§¤íŠ¸ë¦¬ìŠ¤ ì •ë³´:
{context}{intent_info}

ìƒë‹´ ê°€ì´ë“œë¼ì¸:
1. ê³ ê°ì˜ ìš”êµ¬ì‚¬í•­ì„ ì •í™•íˆ íŒŒì•…í–ˆìŒì„ ë³´ì—¬ì£¼ì„¸ìš”
2. ê°€ì¥ ì í•©í•œ ë§¤íŠ¸ë¦¬ìŠ¤ 1-2ê°œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì¶”ì²œí•˜ì„¸ìš”
3. ì¶”ì²œí•˜ëŠ” ì´ìœ ë¥¼ ëª…í™•íˆ ì„¤ëª…í•˜ì„¸ìš”
4. ê°€ê²© ëŒ€ë¹„ íš¨ê³¼ë¥¼ ì–¸ê¸‰í•˜ì„¸ìš”
5. ì¶”ê°€ ê³ ë ¤ì‚¬í•­ì´ë‚˜ íŒì„ ì œê³µí•˜ì„¸ìš”
6. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”
7. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”
8. 300-400ì ë‚´ì™¸ë¡œ ë‹µë³€í•˜ì„¸ìš”
9. í•„ìš”ì‹œ ì¶”ê°€ ì§ˆë¬¸ì„ ìœ ë„í•˜ì„¸ìš”
"""
            
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_query}
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°± ì‘ë‹µ
            return self._generate_fallback_response(user_query, search_results)
    
    def _generate_fallback_response(self, user_query: str, search_results: List[Dict]) -> str:
        """OpenAI ì—†ì´ ê¸°ë³¸ ì‘ë‹µ ìƒì„±"""
        if not search_results:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì¡°ê±´ì— ë§ëŠ” ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        top_mattress = search_results[0]
        features_text = ', '.join(top_mattress['features'][:2]) if top_mattress['features'] else ''
        
        response = f"ê²€ìƒ‰ ê²°ê³¼, '{top_mattress['name']}'ì„(ë¥¼) ì¶”ì²œë“œë¦½ë‹ˆë‹¤. "
        response += f"{top_mattress['brand']} ë¸Œëœë“œì˜ {top_mattress['type']} íƒ€ì…ìœ¼ë¡œ "
        response += f"{top_mattress['price']}ë§Œì›ì…ë‹ˆë‹¤."
        
        if features_text:
            response += f" ì£¼ìš” íŠ¹ì§•ìœ¼ë¡œëŠ” {features_text} ë“±ì´ ìˆìŠµë‹ˆë‹¤."
        
        if len(search_results) > 1:
            response += f" ë‹¤ë¥¸ ì˜µì…˜ë„ {len(search_results)-1}ê°œ ë” ìˆìœ¼ë‹ˆ ì°¸ê³ í•´ë³´ì„¸ìš”."
        
        return response

class ConversationManager:
    """ëŒ€í™” ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ëŒ€í™” ê´€ë¦¬ì ì´ˆê¸°í™”"""
        self.conversation_history = []
        self.user_context = {}
        self.session_start = datetime.now()
    
    def add_interaction(self, user_query: str, agent_response: str, 
                       search_results: Optional[List[Dict]] = None,
                       user_intent: Optional[Dict] = None):
        """ëŒ€í™” ê¸°ë¡ ì¶”ê°€"""
        interaction = {
            'timestamp': datetime.now().isoformat(),
            'user_query': user_query,
            'agent_response': agent_response,
            'search_results_count': len(search_results) if search_results else 0,
            'user_intent': user_intent
        }
        
        self.conversation_history.append(interaction)
        
        # ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        if user_intent:
            self._update_user_context(user_intent)
    
    def _update_user_context(self, user_intent: Dict):
        """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        if 'budget_range' in user_intent and user_intent['budget_range']:
            self.user_context['budget_range'] = user_intent['budget_range']
        
        if 'health_issues' in user_intent and user_intent['health_issues']:
            if 'health_issues' not in self.user_context:
                self.user_context['health_issues'] = set()
            self.user_context['health_issues'].update(user_intent['health_issues'])
        
        if 'preferences' in user_intent and user_intent['preferences']:
            if 'preferences' not in self.user_context:
                self.user_context['preferences'] = set()
            self.user_context['preferences'].update(user_intent['preferences'])
    
    def get_conversation_summary(self) -> Dict:
        """ëŒ€í™” ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        return {
            'session_duration': str(datetime.now() - self.session_start),
            'total_interactions': len(self.conversation_history),
            'user_context': {k: list(v) if isinstance(v, set) else v 
                           for k, v in self.user_context.items()},
            'last_query': self.conversation_history[-1]['user_query'] if self.conversation_history else None
        }

class MattressAIAgent:
    """ë§¤íŠ¸ë¦¬ìŠ¤ AI ì—ì´ì „íŠ¸ - ReAct íŒ¨í„´ êµ¬í˜„"""
    
    def __init__(self, api_key: Optional[str] = None, data_path: Optional[str] = None):
        """
        ë§¤íŠ¸ë¦¬ìŠ¤ AI ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        
        Args:
            api_key: OpenAI API í‚¤
            data_path: ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        """
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.rag_system, rag_success = setup_rag_system(data_path)
        if not rag_success:
            raise RuntimeError("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨")
        
        # í…ìŠ¤íŠ¸ ìƒì„± ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.text_manager = OpenAITextManager(api_key)
        
        # ëŒ€í™” ê´€ë¦¬ì ì´ˆê¸°í™”
        self.conversation_manager = ConversationManager()
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.is_ready = True
        
        logger.info("ë§¤íŠ¸ë¦¬ìŠ¤ AI ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"RAG ì‹œìŠ¤í…œ: {'âœ…' if rag_success else 'âŒ'}")
        logger.info(f"OpenAI í…ìŠ¤íŠ¸: {'âœ…' if self.text_manager.client else 'âŒ'}")
    
    def process_query(self, user_query: str, n_results: int = 5) -> Dict:
        """
        ReAct íŒ¨í„´ìœ¼ë¡œ ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬
        
        Args:
            user_query: ì‚¬ìš©ì ì§ˆë¬¸
            n_results: ê²€ìƒ‰í•  ê²°ê³¼ ìˆ˜
            
        Returns:
            Dict: ì²˜ë¦¬ ê²°ê³¼
        """
        if not self.is_ready:
            return {
                'error': 'AI ì—ì´ì „íŠ¸ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤',
                'user_query': user_query,
                'timestamp': datetime.now().isoformat()
            }
        
        logger.info(f"AI ì—ì´ì „íŠ¸ ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘: '{user_query}'")
        start_time = time.time()
        
        try:
            # Step 1: Thought - ì‚¬ìš©ì ì˜ë„ ë¶„ì„
            logger.info("Step 1: ì‚¬ìš©ì ì˜ë„ ë¶„ì„")
            user_intent = self.text_manager.analyze_user_intent(user_query)
            
            # Step 2: Action - ì¿¼ë¦¬ ê°œì„  ë° ê²€ìƒ‰ ì‹¤í–‰
            logger.info("Step 2: ì¿¼ë¦¬ ê°œì„  ë° ê²€ìƒ‰")
            enhanced_query = self.text_manager.enhance_query(user_query)
            search_results = self.rag_system.search_mattresses(enhanced_query, n_results)
            
            # Step 3: Observation - ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„
            logger.info("Step 3: ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„")
            if not search_results:
                logger.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # Step 4: Thought - ì‘ë‹µ ì „ëµ ê²°ì • ë° ìƒì„±
            logger.info("Step 4: ì‘ë‹µ ìƒì„±")
            agent_response = self.text_manager.generate_response(
                user_query, search_results, user_intent
            )
            
            # ëŒ€í™” ê¸°ë¡ ì €ì¥
            self.conversation_manager.add_interaction(
                user_query, agent_response, search_results, user_intent
            )
            
            end_time = time.time()
            
            result = {
                'user_query': user_query,
                'enhanced_query': enhanced_query,
                'user_intent': user_intent,
                'search_results': search_results,
                'agent_response': agent_response,
                'total_results': len(search_results),
                'processing_time': round(end_time - start_time, 2),
                'timestamp': datetime.now().isoformat(),
                'success': True
            }
            
            logger.info(f"AI ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì™„ë£Œ ({result['processing_time']}ì´ˆ)")
            return result
            
        except Exception as e:
            logger.error(f"AI ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'error': str(e),
                'user_query': user_query,
                'success': False,
                'timestamp': datetime.now().isoformat()
            }
    
    def get_recommendations(self, criteria: Dict) -> List[Dict]:
        """
        íŠ¹ì • ì¡°ê±´ì— ë§ëŠ” ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œ
        
        Args:
            criteria: ê²€ìƒ‰ ì¡°ê±´ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            List[Dict]: ì¶”ì²œ ë§¤íŠ¸ë¦¬ìŠ¤ ëª©ë¡
        """
        # ì¡°ê±´ì„ ìì—°ì–´ ì¿¼ë¦¬ë¡œ ë³€í™˜
        query_parts = []
        
        if criteria.get('health_issues'):
            query_parts.append(f"ê±´ê°• ë¬¸ì œ: {', '.join(criteria['health_issues'])}")
        
        if criteria.get('budget_max'):
            query_parts.append(f"ì˜ˆì‚° {criteria['budget_max']}ë§Œì› ì´í•˜")
        
        if criteria.get('preferences'):
            query_parts.append(f"ì„ í˜¸ë„: {', '.join(criteria['preferences'])}")
        
        if criteria.get('size'):
            query_parts.append(f"{criteria['size']} ì‚¬ì´ì¦ˆ")
        
        search_query = ' '.join(query_parts) if query_parts else "ì¢‹ì€ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œ"
        
        # ê²€ìƒ‰ ì‹¤í–‰
        results = self.rag_system.search_mattresses(search_query, n_results=10)
        
        # ì¡°ê±´ì— ë§ëŠ” í•„í„°ë§
        filtered_results = []
        for mattress in results:
            # ì˜ˆì‚° í•„í„°
            if criteria.get('budget_max') and mattress['price'] > criteria['budget_max']:
                continue
            
            # ì˜ˆì‚° ìµœì†Œê°’ í•„í„°
            if criteria.get('budget_min') and mattress['price'] < criteria['budget_min']:
                continue
            
            filtered_results.append(mattress)
        
        return filtered_results[:5]  # ìƒìœ„ 5ê°œë§Œ ë°˜í™˜
    
    def compare_mattresses(self, mattress_ids: List[str]) -> Dict:
        """ë§¤íŠ¸ë¦¬ìŠ¤ ë¹„êµ ë¶„ì„"""
        mattresses = []
        for mattress_id in mattress_ids:
            mattress = self.rag_system.get_mattress_by_id(mattress_id)
            if mattress:
                mattresses.append(mattress)
        
        if not mattresses:
            return {'error': 'ë¹„êµí•  ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}
        
        # ë¹„êµ í…Œì´ë¸” ìƒì„±
        comparison = {
            'mattresses': mattresses,
            'comparison_table': {},
            'summary': {}
        }
        
        # ì£¼ìš” ì†ì„±ë³„ ë¹„êµ
        attributes = ['price', 'type', 'brand', 'firmness']
        for attr in attributes:
            comparison['comparison_table'][attr] = [
                mattress.get(attr, 'ì •ë³´ ì—†ìŒ') for mattress in mattresses
            ]
        
        return comparison
    
    def get_agent_status(self) -> Dict:
        """ì—ì´ì „íŠ¸ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        rag_status = self.rag_system.get_system_status()
        conversation_summary = self.conversation_manager.get_conversation_summary()
        
        return {
            'ready': self.is_ready,
            'rag_system': rag_status,
            'openai_available': self.text_manager.client is not None,
            'conversation': conversation_summary,
            'session_start': self.conversation_manager.session_start.isoformat()
        }

# í¸ì˜ í•¨ìˆ˜
def create_mattress_agent(api_key: Optional[str] = None, data_path: Optional[str] = None) -> MattressAIAgent:
    """
    ë§¤íŠ¸ë¦¬ìŠ¤ AI ì—ì´ì „íŠ¸ ìƒì„± í¸ì˜ í•¨ìˆ˜
    
    Args:
        api_key: OpenAI API í‚¤
        data_path: ë§¤íŠ¸ë¦¬ìŠ¤ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        
    Returns:
        MattressAIAgent: ì´ˆê¸°í™”ëœ AI ì—ì´ì „íŠ¸
    """
    try:
        agent = MattressAIAgent(api_key, data_path)
        logger.info("âœ… ë§¤íŠ¸ë¦¬ìŠ¤ AI ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ")
        return agent
    except Exception as e:
        logger.error(f"AI ì—ì´ì „íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        raise

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸ¤– ë§¤íŠ¸ë¦¬ìŠ¤ AI ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # AI ì—ì´ì „íŠ¸ ìƒì„±
        api_key = os.getenv('OPENAI_API_KEY')  # ì„ íƒì‚¬í•­
        agent = create_mattress_agent(api_key)
        
        # ì—ì´ì „íŠ¸ ìƒíƒœ í™•ì¸
        status = agent.get_agent_status()
        print(f"\nğŸ“Š ì—ì´ì „íŠ¸ ìƒíƒœ:")
        print(f"  ì¤€ë¹„ ìƒíƒœ: {status['ready']}")
        print(f"  RAG ì‹œìŠ¤í…œ: {status['rag_system']['initialized']}")
        print(f"  OpenAI ì‚¬ìš©: {status['openai_available']}")
        print(f"  ì €ì¥ëœ ë§¤íŠ¸ë¦¬ìŠ¤: {status['rag_system']['chroma_collection'].get('count', 0)}ê°œ")
        
        # ReAct íŒ¨í„´ í…ŒìŠ¤íŠ¸
        test_queries = [
            "í—ˆë¦¬ í†µì¦ì´ ì‹¬í•´ì„œ ë”±ë”±í•œ ë§¤íŠ¸ë¦¬ìŠ¤ ì°¾ê³  ìˆì–´ìš”. ì˜ˆì‚°ì€ 80ë§Œì› ì •ë„ì…ë‹ˆë‹¤.",
            "ë”ìœ„ë¥¼ ë§ì´ íƒ€ëŠ” í¸ì´ë¼ ì‹œì›í•œ ë§¤íŠ¸ë¦¬ìŠ¤ê°€ í•„ìš”í•´ìš”.",
            "ì‹ í˜¼ë¶€ë¶€ìš©ìœ¼ë¡œ í‚¹ì‚¬ì´ì¦ˆ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”.",
            "100ë§Œì› ì´í•˜ë¡œ ì¢‹ì€ ë¸Œëœë“œ ë§¤íŠ¸ë¦¬ìŠ¤ ìˆë‚˜ìš”?"
        ]
        
        print(f"\nğŸ§ª ReAct íŒ¨í„´ í…ŒìŠ¤íŠ¸:")
        
        for i, query in enumerate(test_queries, 1):
            print(f"\n{'='*60}")
            print(f"í…ŒìŠ¤íŠ¸ {i}: '{query}'")
            print(f"{'='*60}")
            
            result = agent.process_query(query, n_results=3)
            
            if result.get('success'):
                print(f"ğŸ¯ ì‚¬ìš©ì ì˜ë„: {result['user_intent'].get('intent_type', 'unknown')}")
                print(f"ğŸ” ê°œì„ ëœ ì¿¼ë¦¬: '{result['enhanced_query']}'")
                print(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {result['total_results']}ê°œ")
                print(f"â±ï¸ ì²˜ë¦¬ ì‹œê°„: {result['processing_time']}ì´ˆ")
                
                if result['search_results']:
                    top_result = result['search_results'][0]
                    print(f"ğŸ¥‡ 1ìˆœìœ„: {top_result['name']} (ìœ ì‚¬ë„: {top_result['similarity_score']:.3f})")
                
                print(f"\nğŸ¤– AI ì‘ë‹µ:")
                print(f"   {result['agent_response']}")
                
            else:
                print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            
            # API í˜¸ì¶œ ì œí•œ ë°©ì§€
            if i < len(test_queries):
                time.sleep(1)
        
        # ëŒ€í™” ìš”ì•½
        conversation_summary = agent.conversation_manager.get_conversation_summary()
        print(f"\nğŸ“ˆ ëŒ€í™” ìš”ì•½:")
        print(f"  ì´ ìƒí˜¸ì‘ìš©: {conversation_summary['total_interactions']}íšŒ")
        print(f"  ì„¸ì…˜ ì‹œê°„: {conversation_summary['session_duration']}")
        print(f"  ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸: {conversation_summary['user_context']}")
        
        print(f"\nâœ… AI ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print(f"ğŸš€ êµ¬í˜„ëœ ê¸°ëŠ¥:")
        print(f"   âœ… ReAct íŒ¨í„´ (Reason-Act-Observe)")
        print(f"   âœ… ì‚¬ìš©ì ì˜ë„ ë¶„ì„")
        print(f"   âœ… ì¿¼ë¦¬ ê°œì„ ")
        print(f"   âœ… RAG ê²€ìƒ‰")
        print(f"   âœ… ìƒí™©ë³„ ì‘ë‹µ ìƒì„±")
        print(f"   âœ… ëŒ€í™” ê´€ë¦¬")
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        print(f"\nğŸ’¡ ë¬¸ì œ í•´ê²°:")
        print(f"1. RAG ì‹œìŠ¤í…œ: pip install sentence-transformers torch")
        print(f"2. OpenAI API: export OPENAI_API_KEY='your-key' (ì„ íƒì‚¬í•­)")
        print(f"3. ë°ì´í„° íŒŒì¼: data/mattress_data.json í™•ì¸")