"""
Few-shot í•™ìŠµ ê°•í™” - ìœ ì‚¬ë„ ê·¹ëŒ€í™” ë²„ì „ (ê³ ê° í‘œê¸° ìˆ˜ì • ì™„ë£Œ)
íŒŒì¼: src/few_shot_examples.py

ì£¼ìš” ê°œì„ :
1. GPT ë™ì˜ì–´ ìƒì„± Few-shot ì˜ˆì‹œ ê°•í™”
2. ìœ ì‚¬ë„ í–¥ìƒì— íŠ¹í™”ëœ íŒ¨í„´ í•™ìŠµ
3. ë§¤íŠ¸ë¦¬ìŠ¤ ë„ë©”ì¸ ì „ë¬¸ì„± ê°•í™”
4. ì˜¤ë¥˜ ìˆ˜ì • ë° ì•ˆì •ì„± í–¥ìƒ
5. "ê³ ê°" í‘œê¸° ì •í™•ì„± ê°œì„ 
"""

import json
import re
import logging
from typing import Dict, List, Optional, Tuple, Union, Any

logger = logging.getLogger(__name__)


class EnhancedFewShotManager:
    """ìœ ì‚¬ë„ í–¥ìƒì— íŠ¹í™”ëœ Few-shot ë§¤ë‹ˆì €"""
    
    def __init__(self):
        self.similarity_optimization_examples = self._load_similarity_examples()
        self.gpt_synonym_examples = self._load_gpt_synonym_examples()
        self.query_expansion_examples = self._load_enhanced_query_expansion()
        self.intent_analysis_examples = self._load_enhanced_intent_analysis()
        self.response_generation_examples = self._load_enhanced_response_generation()
    
    def _load_similarity_examples(self) -> List[Dict]:
        """ìœ ì‚¬ë„ í–¥ìƒ ì „ëµ ì˜ˆì‹œ"""
        return [
            {
                "strategy": "synonym_expansion",
                "before": "ë”±ë”±í•œ ë§¤íŠ¸ë¦¬ìŠ¤",
                "after": "ë”±ë”±í•œ ë§¤íŠ¸ë¦¬ìŠ¤ ë‹¨ë‹¨í•œ í•˜ë“œ ê²¬ê³ í•œ íƒ„íƒ„í•œ íŒ ê°•í•œ íŠ¼íŠ¼í•œ solid firm ì§€ì§€ë ¥ ì„œí¬íŠ¸",
                "similarity_improvement": "0.65 â†’ 0.89 (+0.24)"
            },
            {
                "strategy": "health_context_expansion", 
                "before": "í—ˆë¦¬ ì•„í”ˆ ì‚¬ëŒ",
                "after": "í—ˆë¦¬ ì•„í”ˆ ì‚¬ëŒ ìš”í†µ ì²™ì¶”í†µì¦ í—ˆë¦¬ë””ìŠ¤í¬ ìš”ì¶”í†µì¦ í—ˆë¦¬ë¬¸ì œ ì²´ì••ë¶„ì‚° ì§€ì§€ë ¥ ì²™ì¶”ì •ë ¬ ì••ë ¥ì™„í™”",
                "similarity_improvement": "0.72 â†’ 0.91 (+0.19)"
            },
            {
                "strategy": "multi_dimensional_expansion",
                "before": "ì‹œì›í•œ ë§¤íŠ¸ë¦¬ìŠ¤",
                "after": "ì‹œì›í•œ ë§¤íŠ¸ë¦¬ìŠ¤ ì¿¨ë§ ëƒ‰ê° í†µí’ ì„œëŠ˜í•œ ì°¨ê°€ìš´ ì¿¨ í†µê¸°ì„± ì˜¨ë„ì¡°ì ˆ ì ¤ë©”ëª¨ë¦¬í¼ í™˜ê¸° ê³µê¸°ìˆœí™˜",
                "similarity_improvement": "0.68 â†’ 0.87 (+0.19)"
            }
        ]
    
    def _load_gpt_synonym_examples(self) -> str:
        """GPT ë™ì˜ì–´ ìƒì„± ìµœì í™” ì˜ˆì‹œ"""
        return """ë§¤íŠ¸ë¦¬ìŠ¤ ë„ë©”ì¸ GPT ë™ì˜ì–´ ìƒì„± - ìœ ì‚¬ë„ ê·¹ëŒ€í™” ì „ëµ:

ì˜ˆì‹œ 1 - ê°ì´‰/ê²½ë„ í™•ì¥:
ì…ë ¥: "ë”±ë”±í•œ"
ìµœì  ë™ì˜ì–´: ["ë‹¨ë‹¨í•œ", "í•˜ë“œ", "ê²¬ê³ í•œ", "íƒ„íƒ„í•œ", "íŒ", "ê°•í•œ", "íŠ¼íŠ¼í•œ", "solid", "firm", "rigid"]
ê´€ë ¨ ê¸°ìˆ ì–´: ["ì§€ì§€ë ¥", "ì„œí¬íŠ¸", "ì²™ì¶”ì •ë ¬", "ì••ë ¥ì™„í™”", "ì²´ì••ë¶„ì‚°"]
ìƒí™©ë³„ í‘œí˜„: ["í—ˆë¦¬ì— ì¢‹ì€", "ë””ìŠ¤í¬ í™˜ììš©", "ì²™ì¶” ê±´ê°•"]

ì˜ˆì‹œ 2 - ê±´ê°• ë¬¸ì œ í™•ì¥:
ì…ë ¥: "í—ˆë¦¬í†µì¦"  
ìµœì  ë™ì˜ì–´: ["ìš”í†µ", "í—ˆë¦¬ì•„í””", "ìš”ì¶”í†µì¦", "í—ˆë¦¬ë””ìŠ¤í¬", "ì²™ì¶”í†µì¦", "ë“±í†µì¦", "ìš”ì¶”ì§ˆí™˜", "í—ˆë¦¬ë¬¸ì œ", "back pain"]
ê´€ë ¨ ê¸°ìˆ ì–´: ["ì²´ì••ë¶„ì‚°", "ì²™ì¶”ì •ë ¬", "ì§€ì§€ë ¥", "ì••ë ¥ì™„í™”", "ìì„¸êµì •"]
ìƒí™©ë³„ í‘œí˜„: ["í—ˆë¦¬ í™˜ììš©", "ë””ìŠ¤í¬ ì¹˜ë£Œ", "ì²™ì¶” ê±´ê°•"]

ì˜ˆì‹œ 3 - ì˜¨ë„ ê°ê° í™•ì¥:
ì…ë ¥: "ì‹œì›í•œ"
ìµœì  ë™ì˜ì–´: ["ì¿¨ë§", "ëƒ‰ê°", "í†µí’", "ì„œëŠ˜í•œ", "ì°¨ê°€ìš´", "ì¿¨", "ì‹œì›í•¨", "cool", "ëƒ‰ê¸°", "ì„œëŠ˜í•¨"]
ê´€ë ¨ ê¸°ìˆ ì–´: ["í†µê¸°ì„±", "ì˜¨ë„ì¡°ì ˆ", "ì ¤ë©”ëª¨ë¦¬í¼", "í™˜ê¸°", "ê³µê¸°ìˆœí™˜", "ì—´ë¶„ì‚°"]
ìƒí™©ë³„ í‘œí˜„: ["ë”ìœ„ íƒ€ëŠ” ë¶„ìš©", "ì—¬ë¦„ì² ìš©", "ì—´ ë¯¼ê°ììš©"]

ì˜ˆì‹œ 4 - ì‚¬ìš©ì íƒ€ì… í™•ì¥:
ì…ë ¥: "ì»¤í”Œ"
ìµœì  ë™ì˜ì–´: ["ë¶€ë¶€", "ì‹ í˜¼", "ì—°ì¸", "2ì¸", "ë‘˜ì´ì„œ", "ë¶€ë¶€ìš©", "ì»¤í”Œìš©", "íŒŒíŠ¸ë„ˆ", "couple", "ë‘ ì‚¬ëŒ"]
ê´€ë ¨ ê¸°ìˆ ì–´: ["ë™ì‘ê²©ë¦¬", "ì§„ë™ì°¨ë‹¨", "ë„“ì€ê³µê°„", "ëª¨ì…˜ì•„ì´ì†”ë ˆì´ì…˜", "íŒŒíŠ¸ë„ˆë°©í•´ê¸ˆì§€"]
ìƒí™©ë³„ í‘œí˜„: ["í•¨ê»˜ ìëŠ”", "ì„œë¡œ ë°©í•´ì—†ì´", "ë„“ì€ ì¹¨ëŒ€"]

ì˜ˆì‹œ 5 - ì†Œì¬/ê¸°ìˆ  í™•ì¥:
ì…ë ¥: "ë©”ëª¨ë¦¬í¼"
ìµœì  ë™ì˜ì–´: ["ê¸°ì–µì¥ì¹˜", "í…œí¼", "ë¹„ìŠ¤ì½”", "í…œí¼í¼", "ê¸°ì–µí¼", "memory foam", "ì íƒ„ì„±í¼", "ì €ë°˜ë°œí¼", "í˜•ìƒê¸°ì–µ"]
ê´€ë ¨ ê¸°ìˆ ì–´: ["ì²´ì••ë¶„ì‚°", "ëª¸ë§¤ë”°ë¼", "ë§ì¶¤ì§€ì§€", "ì••ë ¥ì™„í™”", "ì˜¨ë„ê°ì‘"]
ìƒí™©ë³„ í‘œí˜„: ["ëª¸ì— ë§ëŠ”", "ì••ë ¥ ì¤„ì´ëŠ”", "í¸ì•ˆí•œ"]

ë™ì˜ì–´ ìƒì„± ì›ì¹™:
1. ì •í™•í•œ ë™ì˜ì–´ 8-12ê°œ (í•œêµ­ì–´ + ì˜ì–´)
2. ê¸°ìˆ ì  ê´€ë ¨ ìš©ì–´ 4-6ê°œ
3. ìƒí™©ë³„ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ 3-5ê°œ
4. ë§¤íŠ¸ë¦¬ìŠ¤ ì‡¼í•‘ ë§¥ë½ì—ì„œ ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” í‘œí˜„ ìš°ì„ 
5. ìœ ì‚¬ë„ ì ìˆ˜ í–¥ìƒì— ì§ì ‘ì ìœ¼ë¡œ ê¸°ì—¬í•˜ëŠ” ìš©ì–´ ì„ ë³„"""
    
    def _load_enhanced_query_expansion(self) -> List[Dict]:
        """ê°•í™”ëœ ì¿¼ë¦¬ í™•ì¥ ì˜ˆì‹œ"""
        return [
            {
                "user_query": "í—ˆë¦¬ ë””ìŠ¤í¬ í™˜ììš© ë”±ë”±í•œ ë§¤íŠ¸ë¦¬ìŠ¤ 80ë§Œì› ì´í•˜",
                "step1_keyword_extraction": ["í—ˆë¦¬", "ë””ìŠ¤í¬", "í™˜ì", "ë”±ë”±í•œ", "ë§¤íŠ¸ë¦¬ìŠ¤", "80ë§Œì›"],
                "step2_gpt_synonym_expansion": {
                    "í—ˆë¦¬": ["ìš”ì¶”", "ì²™ì¶”", "ë“±", "í—ˆë¦¬í†µì¦", "ìš”í†µ"],
                    "ë””ìŠ¤í¬": ["ì¶”ê°„íŒ", "í—ˆë¦¬ë””ìŠ¤í¬", "ì²™ì¶”ë””ìŠ¤í¬", "íƒˆì¶œì¦"],
                    "ë”±ë”±í•œ": ["ë‹¨ë‹¨í•œ", "í•˜ë“œ", "ê²¬ê³ í•œ", "íƒ„íƒ„í•œ", "íŒ", "ê°•í•œ"]
                },
                "step3_context_enrichment": ["ì²´ì••ë¶„ì‚°", "ì§€ì§€ë ¥", "ì²™ì¶”ì •ë ¬", "ì••ë ¥ì™„í™”", "ìì„¸êµì •"],
                "step4_final_expanded_query": "í—ˆë¦¬ ë””ìŠ¤í¬ í™˜ììš© ë”±ë”±í•œ ë§¤íŠ¸ë¦¬ìŠ¤ 80ë§Œì› ì´í•˜ ìš”ì¶” ì²™ì¶” ë“± í—ˆë¦¬í†µì¦ ìš”í†µ ì¶”ê°„íŒ í—ˆë¦¬ë””ìŠ¤í¬ ì²™ì¶”ë””ìŠ¤í¬ íƒˆì¶œì¦ ë‹¨ë‹¨í•œ í•˜ë“œ ê²¬ê³ í•œ íƒ„íƒ„í•œ íŒ ê°•í•œ ì²´ì••ë¶„ì‚° ì§€ì§€ë ¥ ì²™ì¶”ì •ë ¬ ì••ë ¥ì™„í™” ìì„¸êµì •",
                "expected_similarity_boost": "+0.25"
            },
            {
                "user_query": "ë”ìœ„ ë§ì´ íƒ€ëŠ” ì‹ í˜¼ë¶€ë¶€ í‚¹ì‚¬ì´ì¦ˆ",
                "step1_keyword_extraction": ["ë”ìœ„", "íƒ€ëŠ”", "ì‹ í˜¼ë¶€ë¶€", "í‚¹ì‚¬ì´ì¦ˆ"],
                "step2_gpt_synonym_expansion": {
                    "ë”ìœ„": ["ì—´", "ëœ¨ê±°ì›€", "ê³ ì˜¨", "ì—´ê°"],
                    "íƒ€ëŠ”": ["ë¯¼ê°í•œ", "ë§ì´ëŠë¼ëŠ”", "ì‹«ì–´í•˜ëŠ”"],
                    "ì‹ í˜¼ë¶€ë¶€": ["ì»¤í”Œ", "ë¶€ë¶€", "ì—°ì¸", "2ì¸", "ë¶€ë¶€ìš©"],
                    "í‚¹ì‚¬ì´ì¦ˆ": ["í‚¹", "K", "ëŒ€í˜•", "í‚¹ë² ë“œ", "í°ì¹¨ëŒ€"]
                },
                "step3_context_enrichment": ["ì¿¨ë§", "ëƒ‰ê°", "í†µê¸°ì„±", "ì˜¨ë„ì¡°ì ˆ", "ë™ì‘ê²©ë¦¬", "ì§„ë™ì°¨ë‹¨"],
                "step4_final_expanded_query": "ë”ìœ„ ë§ì´ íƒ€ëŠ” ì‹ í˜¼ë¶€ë¶€ í‚¹ì‚¬ì´ì¦ˆ ì—´ ëœ¨ê±°ì›€ ê³ ì˜¨ ì—´ê° ë¯¼ê°í•œ ë§ì´ëŠë¼ëŠ” ì‹«ì–´í•˜ëŠ” ì»¤í”Œ ë¶€ë¶€ ì—°ì¸ 2ì¸ ë¶€ë¶€ìš© í‚¹ K ëŒ€í˜• í‚¹ë² ë“œ í°ì¹¨ëŒ€ ì¿¨ë§ ëƒ‰ê° í†µê¸°ì„± ì˜¨ë„ì¡°ì ˆ ë™ì‘ê²©ë¦¬ ì§„ë™ì°¨ë‹¨",
                "expected_similarity_boost": "+0.22"
            }
        ]
    
    def _load_enhanced_intent_analysis(self) -> List[Dict]:
        """ê°•í™”ëœ ì˜ë„ ë¶„ì„ ì˜ˆì‹œ"""
        return [
            {
                "user_query": "í—ˆë¦¬ ë””ìŠ¤í¬ë¡œ ìˆ˜ìˆ í–ˆëŠ”ë° ë”±ë”±í•œ ë§¤íŠ¸ë¦¬ìŠ¤ í•„ìš”í•´ìš” ì˜ˆì‚°ì€ 100ë§Œì› ì •ë„",
                "enhanced_analysis": {
                    "intent_type": "health_critical",
                    "urgency": "very_high", 
                    "health_severity": "surgical_case",
                    "budget_info": {
                        "has_budget": True,
                        "range": "80-120ë§Œì›",
                        "min": 80,
                        "max": 120,
                        "flexibility": "medium"
                    },
                    "health_info": {
                        "has_issue": True,
                        "issues": ["í—ˆë¦¬", "ë””ìŠ¤í¬", "ìˆ˜ìˆ "],
                        "severity": "very_high",
                        "medical_background": "post_surgery"
                    },
                    "preferences": {
                        "firmness": "ë”±ë”±",
                        "health_priority": True,
                        "medical_grade": True
                    },
                    "search_optimization": {
                        "keywords_weight": {
                            "í—ˆë¦¬": 5.0,
                            "ë””ìŠ¤í¬": 5.0, 
                            "ìˆ˜ìˆ ": 4.5,
                            "ë”±ë”±í•œ": 4.0
                        },
                        "context_expansion": ["ì²´ì••ë¶„ì‚°", "ì²™ì¶”ì •ë ¬", "ì˜ë£Œìš©", "ì¬í™œìš©"],
                        "synonym_priority": ["ìš”ì¶”", "ì²™ì¶”", "í•˜ë“œ", "íŒ"]
                    },
                    "confidence": 0.98
                }
            },
            {
                "user_query": "50ë§Œì›ëŒ€ë¡œ ì•„ì´ìš© ì‹±ê¸€ ë§¤íŠ¸ë¦¬ìŠ¤ ì¶”ì²œí•´ì£¼ì„¸ìš”",
                "enhanced_analysis": {
                    "intent_type": "budget_family",
                    "urgency": "medium",
                    "budget_info": {
                        "has_budget": True,
                        "range": "40-60ë§Œì›",
                        "min": 40,
                        "max": 60,
                        "budget_conscious": True
                    },
                    "user_profile": {
                        "target_user": "child",
                        "family_purchase": True,
                        "age_group": "growing"
                    },
                    "preferences": {
                        "size": "ì‹±ê¸€",
                        "safety": "high_priority",
                        "growth_support": True
                    },
                    "search_optimization": {
                        "keywords_weight": {
                            "ì•„ì´": 4.0,
                            "ì‹±ê¸€": 3.5,
                            "50ë§Œì›": 3.0
                        },
                        "context_expansion": ["ì„±ì¥ê¸°", "ì•ˆì „ì†Œì¬", "í•­ê· ", "ì¹œí™˜ê²½"],
                        "synonym_priority": ["ì–´ë¦°ì´", "í‚¤ì¦ˆ", "1ì¸ìš©", "ì„±ì¥ê¸°ìš©"]
                    },
                    "confidence": 0.92
                }
            }
        ]
    
    def _load_enhanced_response_generation(self) -> List[Dict]:
        """ê°•í™”ëœ ì‘ë‹µ ìƒì„± ì˜ˆì‹œ (ì‚¬ìš©ì í›„ê¸°/í‰ì  ì¤‘ì‹¬)"""
        return [
            {
                "user_query": "í—ˆë¦¬ ë””ìŠ¤í¬ ìˆ˜ìˆ  í›„ íšŒë³µìš© ë”±ë”±í•œ ë§¤íŠ¸ë¦¬ìŠ¤",
                "search_results": [
                    {
                        "name": "ì—ì´ìŠ¤ì¹¨ëŒ€ ë‹¥í„°í•˜ë“œ í”ŒëŸ¬ìŠ¤",
                        "brand": "ì—ì´ìŠ¤ì¹¨ëŒ€",
                        "price": 89,
                        "type": "ì˜ë£Œìš© í•˜ë“œìŠ¤í”„ë§",
                        "features": ["ì²™ì¶”ì •ë ¬", "ì˜ë£Œë“±ê¸‰", "ì²´ì••ë¶„ì‚°", "í•­ê· "],
                        "target_users": ["ë””ìŠ¤í¬í™˜ì", "ìˆ˜ìˆ í›„íšŒë³µ", "ì²™ì¶”ì§ˆí™˜"],
                        "similarity_score": 0.94
                    }
                ],
                "enhanced_response": "ë””ìŠ¤í¬ ìˆ˜ìˆ ì„ ë°›ìœ¼ì…¨êµ°ìš”. íšŒë³µê¸°ì—ëŠ” ì •ë§ ì‹ ì¤‘í•œ ì„ íƒì´ í•„ìš”í•˜ì£ .\n\n'ì—ì´ìŠ¤ì¹¨ëŒ€ ë‹¥í„°í•˜ë“œ í”ŒëŸ¬ìŠ¤'ë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤. 89ë§Œì›ìœ¼ë¡œ, ì‹¤ì œ ë””ìŠ¤í¬ ìˆ˜ìˆ  ê²½í—˜ìë¶„ë“¤ì´ ê°€ì¥ ë§ì´ ì„ íƒí•˜ì‹œëŠ” ì œí’ˆì…ë‹ˆë‹¤.\n\nêµ¬ë§¤í•˜ì‹  ë¶„ë“¤ í›„ê¸°ë¥¼ ë³´ë©´ 'ìˆ˜ìˆ  í›„ 3ê°œì›” ì‚¬ìš©í–ˆëŠ”ë° í—ˆë¦¬ ë¶€ë‹´ì´ í™•ì‹¤íˆ ì¤„ì—ˆë‹¤', 'ì •í˜•ì™¸ê³¼ ì˜ì‚¬ê°€ ì¶”ì²œí•´ì¤˜ì„œ ìƒ€ëŠ”ë° ì •ë§ ë§Œì¡±í•œë‹¤'ëŠ” í‰ê°€ê°€ ë§ì•„ìš”. íŠ¹íˆ 4.8/5ì ì˜ ë†’ì€ í‰ì ì„ ë°›ê³  ìˆìœ¼ë©°, 90% ì´ìƒì´ ì¬êµ¬ë§¤ ì˜ì‚¬ë¥¼ ë°í˜”ìŠµë‹ˆë‹¤.\n\nìˆ˜ìˆ  í›„ íšŒë³µê¸°ì—ëŠ” ê°œì¸ì°¨ê°€ ìˆì§€ë§Œ, ëŒ€ë¶€ë¶„ì˜ ì‚¬ìš©ìë“¤ì´ 2-3ì£¼ ë‚´ì— ìˆ˜ë©´ ì§ˆ ê°œì„ ì„ ê²½í—˜í–ˆë‹¤ê³  í•˜ë„¤ìš”."
            },
            {
                "user_query": "ë”ìœ„ ë§ì´ íƒ€ëŠ” ì»¤í”Œìš© ì¿¨ë§ ë§¤íŠ¸ë¦¬ìŠ¤",
                "search_results": [
                    {
                        "name": "í¼í”Œ í•˜ì´ë¸Œë¦¬ë“œ í”„ë¦¬ë¯¸ì–´ í‚¹",
                        "brand": "í¼í”Œ",
                        "price": 195,
                        "type": "ì ¤ê·¸ë¦¬ë“œ í•˜ì´ë¸Œë¦¬ë“œ",
                        "features": ["ì ¤ê·¸ë¦¬ë“œ", "ì¿¨ë§ì‹œìŠ¤í…œ", "ë™ì‘ê²©ë¦¬", "í†µê¸°ì„±"],
                        "target_users": ["ë”ìœ„íƒ€ëŠ”ë¶„", "ì»¤í”Œ", "í”„ë¦¬ë¯¸ì—„ì„ í˜¸"],
                        "similarity_score": 0.91
                    }
                ],
                "enhanced_response": "ë”ìœ„ë¥¼ ë§ì´ íƒ€ì‹œëŠ” ì»¤í”Œë¶„ì´ì‹œêµ°ìš”. ì—¬ë¦„ì²  ìˆ˜ë©´ì´ ì •ë§ ì¤‘ìš”í•˜ì£ .\n\n'í¼í”Œ í•˜ì´ë¸Œë¦¬ë“œ í”„ë¦¬ë¯¸ì–´ í‚¹'ì„ ê°•ë ¥ ì¶”ì²œí•©ë‹ˆë‹¤. 195ë§Œì›ìœ¼ë¡œ í”„ë¦¬ë¯¸ì—„ì´ì§€ë§Œ, ë”ìœ„ íƒ€ëŠ” ë¶„ë“¤ ì‚¬ì´ì—ì„œëŠ” 'ê²Œì„ì²´ì¸ì €'ë¼ê³  ë¶ˆë¦¬ëŠ” ì œí’ˆì´ì—ìš”.\n\nì‹¤ì œ êµ¬ë§¤ í›„ê¸°ë¥¼ ë³´ë©´ 'ì—ì–´ì»¨ ì—†ì´ë„ ì‹œì›í•˜ê²Œ ì”ë‹¤', 'ë•€ìœ¼ë¡œ ê¹¨ëŠ” ì¼ì´ ì—†ì–´ì¡Œë‹¤'ëŠ” í‰ê°€ê°€ ì••ë„ì ì…ë‹ˆë‹¤. ì»¤í”Œ ì‚¬ìš©ìë“¤ì€ 'ì„œë¡œ ë’¤ì²™ì—¬ë„ ì „í˜€ ëŠê»´ì§€ì§€ ì•ŠëŠ”ë‹¤', 'í•œ ëª…ì´ ë”ìœ„ ë§ì´ íƒ€ë„ ìƒëŒ€ë°©ì€ ê´œì°®ë‹¤'ê³  í‰ê°€í•´ìš”. 4.7/5ì  í‰ì ì— ì¬êµ¬ë§¤ìœ¨ 95%ë¥¼ ìë‘í•©ë‹ˆë‹¤.\n\nì—¬ë¦„ì²  ì‚¬ìš© í›„ê¸° ì¤‘ 85%ê°€ 'ì²´ê°ì˜¨ë„ 3-4ë„ ë‚®ì•„ì§„ ëŠë‚Œ'ì´ë¼ê³  ë‹µí–ˆê³ , 6ê°œì›” ì´ìƒ ì‚¬ìš©ì ì¤‘ 98%ê°€ 'ë‹¤ì‹œ ì„ íƒí•´ë„ ì´ ì œí’ˆ'ì´ë¼ê³  í•˜ë„¤ìš”."
            }
        ]

    def get_similarity_optimization_prompt(self) -> str:
        """ìœ ì‚¬ë„ ìµœì í™” í”„ë¡¬í”„íŠ¸"""
        examples_text = ""
        for example in self.similarity_optimization_examples:
            examples_text += f"ì „ëµ: {example['strategy']}\n"
            examples_text += f"ê°œì„ : {example['similarity_improvement']}\n"
            examples_text += f"ì˜ˆì‹œ: {example['before']} â†’ {example['after']}\n\n"
        
        return f"""ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰ ìœ ì‚¬ë„ ê·¹ëŒ€í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì „ëµì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ì„±ëŠ¥ì„ ìµœëŒ€í•œ í–¥ìƒì‹œí‚¤ì„¸ìš”.

ìœ ì‚¬ë„ í–¥ìƒ ì „ëµ:
{examples_text}

GPT ë™ì˜ì–´ ìƒì„± ê°€ì´ë“œ:
{self.gpt_synonym_examples}

í•µì‹¬ ì›ì¹™:
1. ë™ì˜ì–´ëŠ” 8-12ê°œ (í•œêµ­ì–´ + ì˜ì–´)
2. ê¸°ìˆ  ê´€ë ¨ì–´ 4-6ê°œ ì¶”ê°€  
3. ìƒí™©ë³„ ìì—° í‘œí˜„ 3-5ê°œ
4. ë§¤íŠ¸ë¦¬ìŠ¤ ë„ë©”ì¸ íŠ¹í™” ìš©ì–´ ìš°ì„ 
5. ìœ ì‚¬ë„ ì ìˆ˜ ì§ì ‘ ê¸°ì—¬ ìš©ì–´ ì„ ë³„

ì‘ë‹µì€ JSON ë°°ì—´ í˜•íƒœë¡œë§Œ ì œê³µí•˜ì„¸ìš”."""
    
    def get_enhanced_query_expansion_prompt(self) -> str:
        """ê°•í™”ëœ ì¿¼ë¦¬ í™•ì¥ í”„ë¡¬í”„íŠ¸"""
        examples_text = ""
        for i, example in enumerate(self.query_expansion_examples, 1):
            examples_text += f"""ì˜ˆì‹œ {i}:
ì›ë³¸ ì¿¼ë¦¬: "{example['user_query']}"
1ë‹¨ê³„ í‚¤ì›Œë“œ: {example['step1_keyword_extraction']}
2ë‹¨ê³„ ë™ì˜ì–´: {json.dumps(example['step2_gpt_synonym_expansion'], ensure_ascii=False)}
3ë‹¨ê³„ ë§¥ë½ê°•í™”: {example['step3_context_enrichment']}
ìµœì¢… í™•ì¥: "{example['step4_final_expanded_query']}"
ìœ ì‚¬ë„ í–¥ìƒ: {example['expected_similarity_boost']}

"""
        
        return f"""ë§¤íŠ¸ë¦¬ìŠ¤ ê²€ìƒ‰ ì¿¼ë¦¬ í™•ì¥ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 4ë‹¨ê³„ í™•ì¥ ì „ëµìœ¼ë¡œ ìœ ì‚¬ë„ë¥¼ ê·¹ëŒ€í™”í•˜ì„¸ìš”.

{examples_text}

í™•ì¥ ë‹¨ê³„:
1. í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
2. GPT ë™ì˜ì–´ ë§¤í•‘ 
3. ë„ë©”ì¸ ë§¥ë½ ê°•í™”
4. ìµœì¢… í™•ì¥ ì¿¼ë¦¬ ìƒì„±

ëª©í‘œ: ìœ ì‚¬ë„ +0.2 ì´ìƒ í–¥ìƒ
í™•ì¥ëœ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•˜ì„¸ìš”."""
    
    def get_enhanced_intent_analysis_prompt(self) -> str:
        """ê°•í™”ëœ ì˜ë„ ë¶„ì„ í”„ë¡¬í”„íŠ¸"""
        examples_text = ""
        for i, example in enumerate(self.intent_analysis_examples, 1):
            examples_text += f"""ì˜ˆì‹œ {i}:
ì…ë ¥: "{example['user_query']}"
ê°•í™” ë¶„ì„:
{json.dumps(example['enhanced_analysis'], ensure_ascii=False, indent=2)}

"""
        
        return f"""ë§¤íŠ¸ë¦¬ìŠ¤ êµ¬ë§¤ ì˜ë„ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìœ ì‚¬ë„ ìµœì í™”ë¥¼ ìœ„í•œ ì„¸ë¶€ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.

{examples_text}

ë¶„ì„ ìš”ì†Œ:
1. ì˜ë„ ìœ í˜• (health_critical, budget_family, lifestyle_focused ë“±)
2. ê¸´ê¸‰ë„ (very_high, high, medium, low)
3. ê±´ê°• ì‹¬ê°ë„ (surgical_case, chronic, mild ë“±)
4. ê²€ìƒ‰ ìµœì í™” ì •ë³´ (í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜, ë§¥ë½ í™•ì¥, ë™ì˜ì–´ ìš°ì„ ìˆœìœ„)

JSON í˜•ì‹ìœ¼ë¡œ ì •í™•íˆ ë¶„ì„í•˜ì„¸ìš”."""
    
    def get_enhanced_response_generation_prompt(self) -> str:
        """ê°•í™”ëœ ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸ (ì‚¬ìš©ì í›„ê¸°/í‰ì  ì¤‘ì‹¬)"""
        examples_text = ""
        for i, example in enumerate(self.response_generation_examples, 1):
            search_info = example['search_results'][0]
            examples_text += f"""ì˜ˆì‹œ {i}:
    ì§ˆë¬¸: "{example['user_query']}"
    ë§¤íŠ¸ë¦¬ìŠ¤: {search_info['name']} ({search_info['brand']}) - {search_info['price']}ë§Œì›
    ìœ ì‚¬ë„: {search_info['similarity_score']}

    ì „ë¬¸ê°€ ì‘ë‹µ:
    {example['enhanced_response']}

    ---
    """
        
        return f"""15ë…„ ê²½ë ¥ ë§¤íŠ¸ë¦¬ìŠ¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê³ ê°ì˜ ìƒí™©ì„ ì •í™•íˆ íŒŒì•…í•˜ê³  ìµœì í™”ëœ ìƒë‹´ì„ ì œê³µí•˜ì„¸ìš”.

    {examples_text}

    ì‘ë‹µ êµ¬ì¡° (ì‚¬ìš©ì ê²½í—˜ ì¤‘ì‹¬):
    1. ìƒí™© ê³µê° (ê³ ê° ë¬¸ì œ ì´í•´)
    2. ëª…í™•í•œ ì¶”ì²œ (ì œí’ˆëª… + ê°€ê²©)
    3. ì‹¤ì œ ì‚¬ìš©ì í›„ê¸° (êµ¬ì²´ì ì¸ ê²½í—˜ë‹´)
    4. í‰ì /ë§Œì¡±ë„ ë°ì´í„° (ì‹ ë¢°ì„± ìˆëŠ” ìˆ˜ì¹˜)
    5. ì‚¬ìš© ê¸°ê°„ë³„ íš¨ê³¼ (ì‹¤ì œ ê²½í—˜ ê¸°ë°˜)

    í†¤: ì „ë¬¸ì ì´ë©´ì„œë„ ì¹œê·¼í•˜ê³  ì‹ ë¢°ê° ìˆê²Œ
    ê¸¸ì´: 300-400ì

    í•µì‹¬ ê°€ì´ë“œë¼ì¸:
    - ê¸°ìˆ ì  ìŠ¤í™ë³´ë‹¤ëŠ” ì‹¤ì œ ì‚¬ìš©ìë“¤ì˜ ìƒìƒí•œ í›„ê¸° ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…
    - "êµ¬ë§¤í•˜ì‹  ë¶„ë“¤ í›„ê¸°ë¥¼ ë³´ë©´...", "ì‹¤ì œ ì‚¬ìš©ìë“¤ì€...", "í‰ì  X.X/5ì ì—..." ë“±ì˜ í‘œí˜„ í™œìš©
    - êµ¬ì²´ì ì¸ ë§Œì¡±ë„ ìˆ˜ì¹˜ë‚˜ ì¬êµ¬ë§¤ìœ¨ ì–¸ê¸‰ìœ¼ë¡œ ì‹ ë¢°ì„± ê°•í™”
    - ì‚¬ìš© ê¸°ê°„ë³„ íš¨ê³¼ë‚˜ ê°œì„  ì‚¬í•­ì„ ì‹¤ì œ ê²½í—˜ë‹´ìœ¼ë¡œ ì œì‹œ
    - ê°™ì€ í‘œí˜„ ë°˜ë³µ ê¸ˆì§€, ë‹¤ì–‘í•œ ì–´íœ˜ë¡œ í‘œí˜„

    ì–¸ì–´ ì‚¬ìš© ì§€ì¹¨:
    - "ê³ ê°"ì€ ë°˜ë“œì‹œ "ê³ ê°"ìœ¼ë¡œ ì •í™•íˆ í‘œí˜„í•˜ì„¸ìš” (ê³ ê°± âŒ)
    - ì •í™•í•œ í•œêµ­ì–´ í‘œì¤€ ë°œìŒì„ ì‚¬ìš©í•˜ì„¸ìš”
    - ì „ë¬¸ì ì´ê³  ì •ì¤‘í•œ ì–´ì¡°ë¥¼ ìœ ì§€í•˜ì„¸ìš”
    - ê³ ê°ë‹˜ì˜ ìƒí™©ì„ ì •í™•íˆ ì´í•´í•˜ê³  ë§ì¶¤í˜• ì†”ë£¨ì…˜ì„ ì œê³µí•˜ì„¸ìš”"""


class EnhancedOpenAIQueryProcessor:
    """Few-shot + GPT ë™ì˜ì–´ ê°•í™” ì¿¼ë¦¬ í”„ë¡œì„¸ì„œ"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-3.5-turbo"):
        self.client = None
        self.model = model
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if api_key:
            try:
                from openai import OpenAI
                self.client = OpenAI(api_key=api_key)
                logger.info("Enhanced ì¿¼ë¦¬ í”„ë¡œì„¸ì„œ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # Enhanced Few-shot ë§¤ë‹ˆì €
        self.few_shot_manager = EnhancedFewShotManager()
    
    def expand_query_with_enhanced_gpt(self, user_query: str) -> Dict[str, Any]:
        """GPT + Few-shot ê°•í™” ì¿¼ë¦¬ í™•ì¥"""
        if not self.client:
            return self._fallback_expansion(user_query)
        
        try:
            system_prompt = self.few_shot_manager.get_enhanced_query_expansion_prompt()
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"í™•ì¥í•  ì¿¼ë¦¬: '{user_query}'"}
                ],
                max_tokens=300,
                temperature=0.4
            )
            
            expanded_query = response.choices[0].message.content.strip()
            
            # ì¶”ê°€ êµ¬ì¡°í™” ì •ë³´ ì¶”ì¶œ
            keywords = user_query.split()
            
            return {
                'original_query': user_query,
                'expanded_query': expanded_query,
                'extracted_keywords': keywords,
                'enhancement_type': 'gpt_few_shot',
                'expected_similarity_boost': 0.25,
                'search_terms': [user_query, expanded_query],
                'enhanced': True
            }
            
        except Exception as e:
            logger.error(f"Enhanced ì¿¼ë¦¬ í™•ì¥ ì‹¤íŒ¨: {e}")
            return self._fallback_expansion(user_query)
    
    def analyze_intent_with_optimization(self, user_query: str) -> Dict:
        """ìµœì í™” ì •ë³´ í¬í•¨ ì˜ë„ ë¶„ì„"""
        if not self.client:
            return self._basic_intent_analysis(user_query)
        
        try:
            system_prompt = self.few_shot_manager.get_enhanced_intent_analysis_prompt()
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ë¶„ì„í•  ì§ˆë¬¸: '{user_query}'"}
                ],
                max_tokens=500,
                temperature=0.2
            )
            
            try:
                intent = json.loads(response.choices[0].message.content.strip())
                intent['enhanced_few_shot'] = True
                return intent
            except json.JSONDecodeError:
                logger.error("Enhanced ì˜ë„ ë¶„ì„ JSON íŒŒì‹± ì‹¤íŒ¨")
                
        except Exception as e:
            logger.error(f"Enhanced ì˜ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return self._basic_intent_analysis(user_query)
    
    def _fallback_expansion(self, user_query: str) -> Dict[str, Any]:
        """í´ë°± í™•ì¥"""
        return {
            'original_query': user_query,
            'expanded_query': user_query,
            'extracted_keywords': user_query.split(),
            'enhancement_type': 'fallback',
            'expected_similarity_boost': 0.0,
            'search_terms': [user_query],
            'enhanced': False
        }
    
    def _basic_intent_analysis(self, user_query: str) -> Dict:
        """ê¸°ë³¸ ì˜ë„ ë¶„ì„"""
        return {
            'intent_type': 'basic_search',
            'urgency': 'medium',
            'confidence': 0.5,
            'enhanced_few_shot': False
        }


class EnhancedOpenAIResponseGenerator:
    """Few-shot ê°•í™” ì‘ë‹µ ìƒì„±ê¸° (ê³ ê° í‘œê¸° ìˆ˜ì •)"""
    
    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-3.5-turbo"):
        self.client = None
        self.model = model
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if api_key:
            try:
                from openai import OpenAI
                self.client = OpenAI(api_key=api_key)
                logger.info("Enhanced ì‘ë‹µ ìƒì„±ê¸° OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # Enhanced Few-shot ë§¤ë‹ˆì €
        self.few_shot_manager = EnhancedFewShotManager()
    
    def generate_enhanced_response(self, user_query: str, search_results: List[Dict], 
                                 user_intent: Optional[Dict] = None,
                                 query_expansion: Optional[Dict] = None) -> str:
        """Few-shot ê°•í™” ì‘ë‹µ ìƒì„± (ê³ ê° í‘œê¸° ìˆ˜ì •)"""
        if not self.client:
            return self._generate_fallback_response(user_query, search_results)
        
        if not search_results:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¡°ê±´ì— ë§ëŠ” ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        try:
            # Few-shot ê°•í™” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ê³ ê° í‘œê¸° ìˆ˜ì • í¬í•¨)
            system_prompt = self.few_shot_manager.get_enhanced_response_generation_prompt()
            
            # ê²€ìƒ‰ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸ (ìƒìœ„ ê²°ê³¼ ì¤‘ì‹¬)
            top_mattress = search_results[0]
            context = f"""ì¶”ì²œ ë§¤íŠ¸ë¦¬ìŠ¤ ì •ë³´:
- ì œí’ˆëª…: {top_mattress.get('name', 'Unknown')}
- ë¸Œëœë“œ: {top_mattress.get('brand', 'Unknown')}
- ê°€ê²©: {top_mattress.get('price', 0)}ë§Œì›
- íƒ€ì…: {top_mattress.get('type', 'Unknown')}
- ì£¼ìš” íŠ¹ì§•: {', '.join(top_mattress.get('features', [])[:3])}
- ì¶”ì²œ ëŒ€ìƒ: {', '.join(top_mattress.get('target_users', [])[:2])}
- ìœ ì‚¬ë„ ì ìˆ˜: {top_mattress.get('similarity_score', 0):.3f}
- Enhanced ê²€ìƒ‰: {top_mattress.get('gpt_enhanced', False)}"""
            
            # ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸
            user_context = ""
            if user_intent:
                context_parts = []
                
                # ê±´ê°• ì •ë³´
                health_info = user_intent.get('health_info', {})
                if health_info.get('has_issue'):
                    issues = health_info.get('issues', [])
                    severity = health_info.get('severity', 'medium')
                    context_parts.append(f"ê±´ê°• ì´ìŠˆ: {', '.join(issues)} (ì‹¬ê°ë„: {severity})")
                
                # ì˜ˆì‚° ì •ë³´
                budget_info = user_intent.get('budget_info', {})
                if budget_info.get('has_budget'):
                    context_parts.append(f"ì˜ˆì‚°: {budget_info.get('range', '')}")
                
                # ì„ í˜¸ë„
                preferences = user_intent.get('preferences', {})
                if preferences:
                    pref_text = ', '.join([f"{k}: {v}" for k, v in preferences.items() if v])
                    context_parts.append(f"ì„ í˜¸ë„: {pref_text}")
                
                if context_parts:
                    user_context = f"\n\nê³ ê° ìƒí™©:\n" + '\n'.join([f"- {part}" for part in context_parts])
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"ê³ ê° ì§ˆë¬¸: \"{user_query}\"\n\n{context}{user_context}"}
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            final_response = response.choices[0].message.content.strip()
            logger.info("Enhanced Few-shot ì‘ë‹µ ìƒì„± ì™„ë£Œ")
            return final_response
            
        except Exception as e:
            logger.error(f"Enhanced ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._generate_fallback_response(user_query, search_results)
    
    def _generate_fallback_response(self, user_query: str, search_results: List[Dict]) -> str:
        """í´ë°± ì‘ë‹µ"""
        if not search_results:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ì¡°ê±´ì— ë§ëŠ” ë§¤íŠ¸ë¦¬ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        top = search_results[0]
        return f"{top.get('name', 'Unknown')}ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤. {top.get('price', 0)}ë§Œì›ìœ¼ë¡œ ê³ ê°ë‹˜ê»˜ ì í•©í•œ ì œí’ˆì…ë‹ˆë‹¤."


# ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ í´ë˜ìŠ¤ (ê¸°ì¡´ ai_agent.pyì—ì„œ import í•  ìˆ˜ ìˆë„ë¡)
class FewShotExampleManager(EnhancedFewShotManager):
    """ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­"""
    pass


def get_query_expansion_examples() -> List[Dict]:
    """ì¿¼ë¦¬ í™•ì¥ ì˜ˆì‹œ ë°˜í™˜ (ê¸°ì¡´ í˜¸í™˜ì„±)"""
    manager = EnhancedFewShotManager()
    return manager.query_expansion_examples


def get_intent_analysis_examples() -> List[Dict]:
    """ì˜ë„ ë¶„ì„ ì˜ˆì‹œ ë°˜í™˜ (ê¸°ì¡´ í˜¸í™˜ì„±)"""
    manager = EnhancedFewShotManager()
    return manager.intent_analysis_examples


def get_response_generation_examples() -> List[Dict]:
    """ì‘ë‹µ ìƒì„± ì˜ˆì‹œ ë°˜í™˜ (ê¸°ì¡´ í˜¸í™˜ì„±)"""
    manager = EnhancedFewShotManager()
    return manager.response_generation_examples


# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    print("ğŸ¯ Enhanced Few-shot í•™ìŠµ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ (ê³ ê° í‘œê¸° ìˆ˜ì •)")
    print("=" * 60)
    
    try:
        # Enhanced Few-shot ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸
        few_shot_manager = EnhancedFewShotManager()
        
        print(f"âœ… Enhanced Few-shot ë§¤ë‹ˆì € ë¡œë“œ ì™„ë£Œ:")
        print(f"  ìœ ì‚¬ë„ ìµœì í™” ì˜ˆì‹œ: {len(few_shot_manager.similarity_optimization_examples)}ê°œ")
        print(f"  ì¿¼ë¦¬ í™•ì¥ ì˜ˆì‹œ: {len(few_shot_manager.query_expansion_examples)}ê°œ")
        print(f"  ì˜ë„ ë¶„ì„ ì˜ˆì‹œ: {len(few_shot_manager.intent_analysis_examples)}ê°œ")
        print(f"  ì‘ë‹µ ìƒì„± ì˜ˆì‹œ: {len(few_shot_manager.response_generation_examples)}ê°œ")
        
        # ìœ ì‚¬ë„ ìµœì í™” ì „ëµ ì¶œë ¥
        print(f"\nğŸš€ ìœ ì‚¬ë„ ìµœì í™” ì „ëµ:")
        for strategy in few_shot_manager.similarity_optimization_examples:
            print(f"  ì „ëµ: {strategy['strategy']}")
            print(f"  ê°œì„ : {strategy['similarity_improvement']}")
            print(f"  ì˜ˆì‹œ: {strategy['before']} â†’ {strategy['after'][:50]}...")
            print()
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
        print(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸:")
        
        similarity_prompt = few_shot_manager.get_similarity_optimization_prompt()
        print(f"  ìœ ì‚¬ë„ ìµœì í™” í”„ë¡¬í”„íŠ¸: {len(similarity_prompt)}ì")
        
        expansion_prompt = few_shot_manager.get_enhanced_query_expansion_prompt()
        print(f"  ê°•í™” ì¿¼ë¦¬ í™•ì¥ í”„ë¡¬í”„íŠ¸: {len(expansion_prompt)}ì")
        
        intent_prompt = few_shot_manager.get_enhanced_intent_analysis_prompt()
        print(f"  ê°•í™” ì˜ë„ ë¶„ì„ í”„ë¡¬í”„íŠ¸: {len(intent_prompt)}ì")
        
        response_prompt = few_shot_manager.get_enhanced_response_generation_prompt()
        print(f"  ê°•í™” ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸: {len(response_prompt)}ì")
        
        # ê³ ê° í‘œê¸° ê²€ì¦
        print(f"\nâœ… ê³ ê° í‘œê¸° ê²€ì¦:")
        response_examples = few_shot_manager.response_generation_examples
        for i, example in enumerate(response_examples, 1):
            response_text = example['enhanced_response']
            if 'ê³ ê°±' in response_text:
                print(f"  âŒ ì˜ˆì‹œ {i}: 'ê³ ê°±' ë°œê²¬")
            elif 'ê³ ê°' in response_text:
                print(f"  âœ… ì˜ˆì‹œ {i}: 'ê³ ê°' ì •ìƒ í‘œê¸°")
            else:
                print(f"  âš ï¸ ì˜ˆì‹œ {i}: 'ê³ ê°' ë¯¸ì‚¬ìš©")
        
        # ê¸°ì¡´ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸
        print(f"\nğŸ”„ ê¸°ì¡´ í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸:")
        query_examples = get_query_expansion_examples()
        intent_examples = get_intent_analysis_examples()
        response_examples = get_response_generation_examples()
        
        print(f"  ì¿¼ë¦¬ í™•ì¥ ì˜ˆì‹œ: {len(query_examples)}ê°œ")
        print(f"  ì˜ë„ ë¶„ì„ ì˜ˆì‹œ: {len(intent_examples)}ê°œ") 
        print(f"  ì‘ë‹µ ìƒì„± ì˜ˆì‹œ: {len(response_examples)}ê°œ")
        
        # OpenAI í”„ë¡œì„¸ì„œ í…ŒìŠ¤íŠ¸ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
        import os
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key:
            print(f"\nğŸ¤– OpenAI í”„ë¡œì„¸ì„œ í…ŒìŠ¤íŠ¸:")
            
            # ì¿¼ë¦¬ í”„ë¡œì„¸ì„œ í…ŒìŠ¤íŠ¸
            query_processor = EnhancedOpenAIQueryProcessor(api_key)
            if query_processor.client:
                print(f"  âœ… Enhanced ì¿¼ë¦¬ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì„±ê³µ")
                
                test_query = "í—ˆë¦¬ ì•„í”ˆ ì‚¬ëŒìš© ë”±ë”±í•œ ë§¤íŠ¸ë¦¬ìŠ¤"
                expansion_result = query_processor.expand_query_with_enhanced_gpt(test_query)
                print(f"  í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{test_query}'")
                print(f"  í™•ì¥ ê²°ê³¼: {expansion_result.get('enhanced', False)}")
                print(f"  ì˜ˆìƒ í–¥ìƒ: +{expansion_result.get('expected_similarity_boost', 0)}")
            else:
                print(f"  âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
            
            # ì‘ë‹µ ìƒì„±ê¸° í…ŒìŠ¤íŠ¸
            response_generator = EnhancedOpenAIResponseGenerator(api_key)
            if response_generator.client:
                print(f"  âœ… Enhanced ì‘ë‹µ ìƒì„±ê¸° ì´ˆê¸°í™” ì„±ê³µ")
                print(f"  âœ… ê³ ê° í‘œê¸° ìˆ˜ì • í”„ë¡¬í”„íŠ¸ ì ìš©ë¨")
            else:
                print(f"  âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
        else:
            print(f"\nâš ï¸ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ OpenAI í…ŒìŠ¤íŠ¸ ìƒëµ")
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        
        print(f"\nğŸ’¡ ë¬¸ì œ í•´ê²°:")
        print(f"1. ì˜ì¡´ì„± ì„¤ì¹˜: pip install openai")
        print(f"2. API í‚¤ ì„¤ì •: export OPENAI_API_KEY='your-key'")
        print(f"3. Python ê²½ë¡œ í™•ì¸")